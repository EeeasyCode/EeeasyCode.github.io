{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"1. 서버리스란 무엇인가? 서버리스(Serverless)는 개발자와 인프라 엔지니어가 서버 관리의 부담에서 벗어나 애플리케이션 로직에 집중할 수 있게 해준다고 해요. 2014년 AWS Lambda의 출시와 함께 본격적으로 주목받기 시작했으며, 이는 클라우드의 Auto Scaling과 Event-driven 컴퓨팅 기술 발전의 결과물이기도 하죠. AWS S…","fields":{"slug":"/serverless_architecture/"},"frontmatter":{"date":"March 02, 2025","title":"서버리스 아키텍처의 진짜 의미와 오해","tags":["serverless","infra"]},"rawMarkdownBody":"\n## 1. 서버리스란 무엇인가?\n\n서버리스(Serverless)는 개발자와 인프라 엔지니어가 서버 관리의 부담에서 벗어나 애플리케이션 로직에 집중할 수 있게 해준다고 해요. 2014년 AWS Lambda의 출시와 함께 본격적으로 주목받기 시작했으며, 이는 클라우드의 **Auto Scaling**과 **Event-driven** 컴퓨팅 기술 발전의 결과물이기도 하죠.\n\n![AWS Serverless Architecture Diagram](https://i.imgur.com/oSCGcF2.png)\n\n### 서버리스의 핵심 특징\n\n- **Auto Scaling**: 트래픽 부하에 따라 인스턴스가 자동으로 생성되고 제거됩니다.\n- **관리형 인프라**: 서버 프로비저닝, 패치 관리, 로드 밸런싱 등 인프라 운영 부담이 최소화됩니다.\n- **Event Driven**: S3 업로드, API 호출, 메시지 큐 등 특정 이벤트가 발생하면 함수가 실행됩니다.\n- **비용 효율성**: 사용한 리소스만큼만 과금되는 **Pay-as-you-go** 모델로, 유휴 서버 비용이 없습니다.\n\n> **인프라 관점 인사이트**: 서버리스는 전통적인 VM 기반 인프라에서 벗어나 클라우드 제공자가 하드웨어와 운영체제 레벨을 추상화한 결과로, 인프라 팀의 역할이 \"서버 관리\"에서 \"아키텍처 설계와 모니터링\"으로 전환되고 있어요.\n\n## 2. 서버리스의 대표적인 구현 방식\n\n서버리스는 주로 **FaaS(Function as a Service)** 와 **BaaS(Backend as a Service)** 로 구현되는데요. 주요 클라우드 벤더별 서비스를 살펴보면 다음과 같아요.\n\n| 서비스                 | 제공 업체  | 주요 특징                                  |\n| ---------------------- | ---------- | ------------------------------------------ |\n| AWS Lambda             | AWS        | 다양한 이벤트 소스 트리거, 강력한 생태계   |\n| Google Cloud Functions | GCP        | Firebase와 연동 강점, NoSQL 친화적         |\n| Azure Functions        | Azure      | .NET 개발자 친화적, Durable Functions 지원 |\n| Cloudflare Workers     | Cloudflare | 엣지에서 실행, 초저지연 응답 속도          |\n\n### FaaS vs BaaS\n\n- **FaaS**: AWS Lambda처럼 개별 함수 단위로 코드가 실행되며, 인프라 엔지니어는 이벤트 트리거와 실행 환경만 신경 쓰면 됩니다.\n- **BaaS**: Firebase나 AWS Amplify처럼 인증, 데이터베이스, API Gateway 등 백엔드 기능을 통합 제공해 인프라 설계를 단순화합니다.\n\n> FaaS는 단일 작업 단위에 최적화되어 있고, BaaS는 전체 백엔드 스택을 아우르니 프로젝트 요구사항에 따라 둘을 조합하는 하이브리드 접근도 가능해요.\n\n![](https://i.imgur.com/4CDfBZy.png)\n\n## 3. 서버리스의 장점과 단점\n\n### ✅ 서버리스의 장점\n\n1. **운영 부담 감소**: 서버 프로비저닝, OS 패치, 네트워크 설정 등 인프라 유지보수가 필요 없습니다.\n2. **비용 절감**: 사용량 기반 과금으로 유휴 리소스 비용이 없습니다.\n3. **확장성**: 수평 확장이 자동으로 처리되어 트래픽 급등에도 안정적입니다.\n4. **빠른 개발**: MVP(최소 기능 제품) 구축 속도가 빨라집니다.\n5. **이벤트 기반 설계**: 실시간 데이터 처리와 같은 이벤트 드리븐 시스템에 적합합니다.\n\n### ⚠️ 서버리스의 단점\n\n1. **콜드 스타트**: 초기 요청 시 지연이 발생하며, Java나 .NET 같은 무거운 런타임에서 두드러집니다.\n2. **벤더 락인**: 특정 클라우드 벤더의 생태계에 종속될 위험이 큽니다.\n3. **트랜잭션 관리**: 상태 유지(Stateful) 워크로드에는 부적합합니다.\n4. **실행 시간 제한**: Lambda의 경우 최대 15분으로, 장시간 작업에 제약이 있습니다.\n5. **모니터링 복잡성**: 분산 환경에서 로깅과 디버깅이 더 까다롭습니다.\n\n> 콜드 스타트는 프로비저닝된 동시성(Provisioned Concurrency)으로 완화할 수 있지만 추가 비용이 발생해요. 벤더 락인을 줄이려면 오픈소스 프레임워크(Serverless Framework 등)를 활용하는 것도 방법이 되겠네요.\n\n## 4. 서버리스에 대한 흔한 오해\n\n### ❌ 오해 1: “서버리스는 서버가 없는 것이다?”\n\n서버리스는 **“서버가 없는(Server-less)”** 것이 아니라 **“서버를 신경 쓰지 않아도 되는(Server-abstracted)”** 아키텍처에요. 실제로는 클라우드 제공자의 서버에서 실행되지만, 인프라 관리를 우리가 직접 하지 않는다는 점이 핵심이죠.\n\n### ❌ 오해 2: “서버리스는 항상 비용이 저렴하다?”\n\n짧고 간헐적인 트래픽에서는 비용 효율적이지만, 지속적인 고부하 트래픽에서는 EC2 같은 전통 인프라가 더 저렴할 수 있어요.\n\n- **예시**: EC2 월 $30 고정 비용 vs Lambda 호출 횟수 증가 시 비용 상승.\n\n### ❌ 오해 3: “모든 애플리케이션에 적합하다?”\n\n이벤트 기반 시스템이나 API 백엔드에는 적합하지만, 고성능 컴퓨팅이나 상태 유지 애플리케이션에는 한계가 있어요.\n\n### ❌ 오해 4: “서버리스면 DevOps가 필요 없다?”\n\n여전히 배포 파이프라인, 모니터링(AWS X-Ray, CloudWatch), 보안 설정이 필요합니다. 인프라 팀의 역할이 \"관리\"에서 \"최적화\"로 바뀔 뿐이에요.\n\n## 5. 서버리스를 도입해야 할 때와 피해야 할 때\n\n### ✅ 도입에 적합한 경우\n\n- **이벤트 기반 워크로드**: 파일 업로드 후 자동 처리 등.\n- **변동 트래픽**: 크리스마스 시즌 같은 대규모 이벤트.\n- **빠른 개발**: 스타트업의 MVP 제작.\n- **IoT/실시간 처리**: 센서 데이터 처리, 챗봇 등.\n\n### ❌ 피해야 할 경우\n\n- **고성능 컴퓨팅**: 머신러닝 학습처럼 CPU 집약적인 작업.\n- **장시간 작업**: 배치 프로세싱(대안으로 ECS나 Batch 추천).\n- **복잡한 트랜잭션**: 상태 관리와 롤백이 중요한 시스템.\n- **지속 고부하**: Kubernetes로 컨테이너 오케스트레이션이 더 나음.\n\n## 6. 내가 서버리스 아키텍처에 빠진 이유?!\n\n최근 진행한 프로젝트들은 인증/인가부터 간단한 데이터 서빙, 저장 등 다양한 부분에서 서버리스 아키텍처 기반으로 설계하고 있어요.\n\n특히, AWS Lambda, DynamoDB를 정말 잘 사용하고 있는데, Cognito 등 AWS에서 제공하는 다양한 서비스들과 연동하기도 편리하고 1인 개발을 할 때에 인프라 구축에 들어가는 비용을 절감할 수 있다는 점이 너무 좋은 것 같아요.\n\n중요 비즈니스 로직, 유휴 시간이 상대적으로 짧은 서비스들은 EC2 내에서 돌리지만 나머지는 대부분 Function 형태로 분리해서 설계하고 있구요.\n\n토이 프로젝트에서 가장 중요한 부분 중에 하나는 비용이잖아요? 사실, 우리가 간단하게 만드는 프로젝트는 대부분 무료 제공 할당량 내에 존재하기에 서버리스 서비스를 사용해도 비용이 들지 않는 장점도 있구요.\n\n이렇게 좋고 편리한 서버리스 아키텍처도 만능이 아니라는 것에 대해서는 계속 염두해두고 사용 중이에요.\n\n## 7. 결론: 서버리스는 강력하지만 만능은 아니다\n\n서버리스는 인프라 관리 부담을 줄이고 빠른 개발과 확장성을 제공하는 강력한 도구에요. 하지만 콜드 스타트, 벤더 락인, 트랜잭션 관리의 한계를 고려해야 해요. 도입 전에는 다음을 점검하는게 좋을 것 같아요.\n\n- **비용 분석**: 트래픽 패턴에 따른 Lambda vs EC2 비교\n- **성능 요구사항**: 콜드 스타트 허용 범위 확인\n- **운영 전략**: 모니터링 및 배포 파이프라인 설계\n\n적절히 활용하면 서버리스는 클라우드 환경에서 인프라 엔지니어와 개발자 모두에게 혁신적인 가치를 제공할 수 있다는 것은 분명하다고 생각해요.\n\n토이 프로젝트를 생각하고 계신 분들, 이참에 서버리스 아키텍처로 도전해보시는 거 어때요?\n"},{"excerpt":"NestJS 관련된 글을 몇 개 작성했었는데, 최근들어 NestJS에 대해 더 깊이 파보고 싶다는 생각이 들었다. 그래서, 이왕 이렇게 된 거 끝까지 극한으로 파헤쳐보려고 한다. 카테고리 자체는 공식 문서 정리, 성능 개선, 오픈소스 기여 등 다양하게 가져가볼 계획이고, 시리즈는 전부 NestJS에 넣을 생각이다. NestJS Deep Dive Repos…","fields":{"slug":"/nestjs/"},"frontmatter":{"date":"February 05, 2025","title":"NestJS Deep Dive","tags":["NestJS"]},"rawMarkdownBody":"\nNestJS 관련된 글을 몇 개 작성했었는데, 최근들어 NestJS에 대해 더 깊이 파보고 싶다는 생각이 들었다. 그래서, 이왕 이렇게 된 거 끝까지 극한으로 파헤쳐보려고 한다.\n\n<br>\n\n카테고리 자체는 공식 문서 정리, 성능 개선, 오픈소스 기여 등 다양하게 가져가볼 계획이고, 시리즈는 전부 NestJS에 넣을 생각이다.\n\n<br>\n\n> **NestJS Deep Dive Repository** <br> https://github.com/EeeasyCode/dive-to-nestjs\n"},{"excerpt":"AWS Lambda의 Execution Environment 이해하기 AWS Lambda 는 서버리스 컴퓨팅의 핵심 서비스로, 서버 관리 없이 코드를 실행할 수 있게 해줍니다. 이러한 편리함 뒤에는 'Execution Environment(실행 환경)' 라는 개념이 중요한 역할을 한다고 하는데요. 이번 글에서는 AWS Lambda의 Execution En…","fields":{"slug":"/lambda-exectution-environment/"},"frontmatter":{"date":"January 19, 2025","title":"AWS Lambda의 Execution Environment 이해하기","tags":["aws-lambda","serverless"]},"rawMarkdownBody":"\n# AWS Lambda의 Execution Environment 이해하기\n\n**AWS Lambda** 는 서버리스 컴퓨팅의 핵심 서비스로, 서버 관리 없이 코드를 실행할 수 있게 해줍니다. 이러한 편리함 뒤에는 **'Execution Environment(실행 환경)'** 라는 개념이 중요한 역할을 한다고 하는데요. 이번 글에서는 AWS Lambda의 Execution Environment가 무엇인지, 어떻게 동작하는지, 그리고 이를 최적화하여 활용하는 방법에 대해 알아보겠습니다.\n\n## Execution Environment\n\nExecution Environment는 Lambda 함수가 실행되는 격리된 환경으로, 함수 실행에 필요한 모든 리소스를 관리합니다. 각 Execution Environment는 다음과 같은 구성 요소를 포함합니다.\n\n- **메모리(Memory)** : 함수에 할당된 메모리 용량으로, 함수 생성 시 설정함\n- **CPU** : 할당된 메모리에 비례하여 CPU 성능이 결정됨\n- **임시 스토리지(Ephemeral Storage)** : 함수 실행 중 `/tmp` 디렉터리를 통해 최대 512MB의 임시 스토리지를 제공함\n- **타임아웃(Timeout)** : 함수의 최대 실행 시간을 설정하며, 기본값은 3초, 최대 15분까지 가능함\n- **핸들러(Handler)** : 함수의 진입점으로, 이벤트를 처리하는 메인 메서드\n- **프로비저닝된 동시성(Provisioned Concurrency)** : 함수의 초기화를 미리 수행하여 콜드 스타트 지연을 최소화하는 옵션\n- **환경 변수(Environment Variables)** : 함수 실행 시 필요한 설정값들을 저장함\n\n각 함수는 고유한 Execution Environment에서 실행되며, 함수 간에 이 환경이 공유되지 않습니다. 그러나 동일한 함수가 반복 호출될 경우, 동일한 Execution Environment가 재사용될 수 있습니다. 이러한 재사용 특성은 함수의 성능 최적화에 중요한 영향을 미칩니다.\n\n## Execution Environment의 생명주기\n\nExecution Environment는 함수 실행 시 다음과 같은 단계를 거칩니다.\n\n![Lambda 실행 환경 수명 주기](aws-lambda.png)\n\n1. **초기화 단계(Init)**\n\n   - **Extension Init** : Lambda에 부가 기능을 추가하는 확장 프로그램을 초기화합니다.\n   - **Runtime Init** : 선택한 언어의 런타임을 초기화하여 코드 실행을 준비합니다.\n   - **Function Init** : 함수의 정적 코드를 실행하여 핸들러를 준비합니다.\n\n   이 단계는 함수의 첫 호출 시 발생하며, 최대 10초의 지연이 생길 수 있습니다. 이러한 지연을 **'콜드 스타트(Cold Start)'**라고 합니다. **프로비저닝된 동시성**을 사용하면 이 지연을 최소화할 수 있습니다.\n\n2. **호출 단계(Invoke)**\n   실제 함수의 비즈니스 로직이 실행되는 단계로, 설정된 타임아웃 내에 완료되어야 합니다.\n\n3. **종료 단계(Shutdown)**\n   함수 실행이 완료되면 런타임과 확장 프로그램을 종료하고, Execution Environment를 정리합니다. 이 단계는 최대 2초가 주어지며, 이후 강제로 종료됩니다.\n\n## Execution Environment의 재사용과 최적화\n\nLambda는 성능 최적화를 위해 종료 단계 이후에도 Execution Environment를 일정 시간 유지합니다. 이로 인해 다음과 같은 이점이 있는데요,\n\n- **전역 변수의 유지**\n\n핸들러 외부에서 초기화된 변수나 객체는 Execution Environment가 재사용될 때 그대로 유지됩니다. 이 환경이 유지되어 전역변수로 만들어진 객체들의 참조가 지속적으로 남아있는 것이죠. </br>\n\n예를 들어, 데이터베이스 연결을 전역 변수로 선언하면 첫 호출 이후 재사용되어 성능이 향상됩니다.\n\n```javascript\n// 초기화 코드\nlet dbConnection\n\nif (!dbConnection) {\n  dbConnection = initializeDBConnection()\n}\n\nexports.handler = async event => {\n  // dbConnection을 사용한 로직\n}\n```\n\n- **임시 스토리지의 재사용**\n\n<code>/tmp</code> 디렉터리에 저장된 파일은 Execution Environment가 유지되는 한 다음 호출 시에도 접근 가능합니다. 이를 활용하여 캐시나 임시 데이터를 저장할 수 있습니다.\n\n- **백그라운드 프로세스의 지속**\n\n함수 종료 시 완료되지 않은 백그라운드 작업이나 콜백 함수는 Execution Environment 재사용 시 다시 실행될 수 있는데요, NodeJS 기반에서 Promise가 다음 함수에서 resolve 되어버리는 문제가 발생할 수 있습니다.\n\n## 최적화 사례\n\n- **전역 변수 활용**\n\n데이터베이스 연결이나 외부 API 클라이언트 등 재사용 가능한 객체는 전역 변수로 선언하여 초기화 비용을 절감\n\n- **임시 스토리지 활용**\n\n반복적으로 필요한 데이터는 <code>/tmp</code> 디렉터리에 저장하여 I/O 비용을 최소화\n\n- **프로비저닝된 동시성 사용**\n\n콜드 스타트 지연이 허용되지 않는 경우, 프로비저닝된 동시성을 설정하여 항상 준비된 Execution Environment를 유지시킬 수 있음\n\n## 마무리\n\nAWS Lambda의 Execution Environment는 함수의 성능과 효율성에 직접적인 영향을 미칩니다. 그 동작 원리와 생명주기를 깊이 이해하고 적절히 활용하면 서버리스 애플리케이션의 성능을 극대화할 수 있습니다. 앞으로 Lambda Extensions나 프로비저닝된 동시성 등 고급 주제에 대해서도 지속적으로 학습하여 더욱 최적화된 서버리스 아키텍처를 구축해보려고 합니다.\n\n감사합니다.\n"},{"excerpt":"안녕하세요, 저는 가천대학교 동아리 모집 관리 서비스를 기획하고 개발한 이창민입니다. 졸업 프로젝트를 위해 저를 포함한 개발자 4명에서 진행하게 된 프로젝트인데요, 서비스 명은 GACHDONG(가츠동) 으로 프로젝트 심사와 보고서 작성으로 인해 심사를 위한 서비스 구현까지만 진행되었고, 종강 이후 더 다양한 기능을 개발할 계획에 있습니다. 서비스 링크 서…","fields":{"slug":"/gachdong-01/"},"frontmatter":{"date":"December 10, 2024","title":"가천대학교 동아리 모집 관리 서비스","tags":["졸업 프로젝트","가천대학교","동아리"]},"rawMarkdownBody":"\n안녕하세요, 저는 가천대학교 동아리 모집 관리 서비스를 기획하고 개발한 이창민입니다.\n\n졸업 프로젝트를 위해 저를 포함한 개발자 4명에서 진행하게 된 프로젝트인데요, 서비스 명은 **GACHDONG(가츠동)** 으로 프로젝트 심사와 보고서 작성으로 인해 심사를 위한 서비스 구현까지만 진행되었고, 종강 이후 더 다양한 기능을 개발할 계획에 있습니다.\n\n[서비스 링크](https://www.gachdong.club/)\n\n서비스 링크로 접속하게 되었을 때, 아직 데이터들이 존재하고 있지 않아 별 기능은 없지만, 저희가 생각하고 있는 다양한 기능을 최대한 빠른 시일 내에 제공하려 합니다 :)\n\n해당 서비스에 대해 궁금한 점 혹은 필요한 기능 등 다양한 피드백을 댓글이나 제 이메일로 연락주시면 됩니다. 감사합니다!\n\n## Gach-dong MSA\n\n- Micro Service Architecture (Gateway Pattern)\n- SpringBoot 3.0 + JDK 17\n- Spring Data JPA\n- Docker based Build & Deploy\n- Prometheus and Grafana for monitoring\n- Istio Ingress Gateway + Service Mesh\n\n## 서비스 소개\n\n![서비스 페이지](https://i.imgur.com/sfTB3Oe.png)\n\n## Cloud Architecture\n\n![아키텍처](https://i.imgur.com/lS1R6Mx.png)\n"},{"excerpt":"최근 프로젝트에서 백오피스를 만들게 되었는데, React로 Front 구현, NodeJS(Express)로 서버 개발을 진행하게 되었다. 백오피스 환경은 전부 무료 클라우드를 사용하고 싶어, React는 Netlify로 배포를 진행했고 NodeJS는 Koyeb로 배포를 진행했다. React는 성공적으로 배포가 되었지만, NodeJS는 배포 과정에서 에러를…","fields":{"slug":"/koyeb-free-tier/"},"frontmatter":{"date":"December 07, 2024","title":"Koyeb에 NodeJS(Express) 서버 배포하기","tags":["koyeb","node.js"]},"rawMarkdownBody":"\n최근 프로젝트에서 백오피스를 만들게 되었는데, **React**로 Front 구현, **NodeJS(Express)**로 서버 개발을 진행하게 되었다. 백오피스 환경은 전부 무료 클라우드를 사용하고 싶어, React는 Netlify로 배포를 진행했고 NodeJS는 Koyeb로 배포를 진행했다. React는 성공적으로 배포가 되었지만, NodeJS는 배포 과정에서 에러를 계속 뱉어냈다.\n\n# NodeJS 배포\n\nKoyeb에서 지원하는 배포 방식에는 크게 두 가지가 있다.\n\n    1. GitHub Repository를 통한 배포\n    2. Docker를 통한 배포\n\n## GitHub Repository 배포\n\n나는 처음에 GitHub Repository를 통해 배포를 시도했다. 배포를 시켜놓고 잠깐 볼 일을 보고오니 에러가 발생해 있었다.\n![](https://velog.velcdn.com/images/eeeasy-code/post/2c8da60d-73d4-47ae-9a7a-4bf8d0ce4db9/image.png)\n\n무슨 문제로 에러가 발생했는지 확인하기 위해서 로그를 확인했다.\n![](https://velog.velcdn.com/images/eeeasy-code/post/e59e0b62-954b-4bb8-ac31-c9dad982c4cd/image.png)\n\n확인 결과, node_modules를 찾지 못해 발생한 에러였다. 기존 런타임 command를 <code> npm start</code>로만 지정해주어 발생한 것으로, <code> npm install; npm start</code>를 입력하면 정상적으로 배포가 수행된다.\n![](https://velog.velcdn.com/images/eeeasy-code/post/090f718f-2025-4efb-8633-0836d00834ea/image.png)\n\n## Docker 배포\n\nGitHub로 배포를 하고나니 시간이 어느정도 여유가 생겨서 Docker Image로 배포하는 방법도 궁금해졌다. 클라우드에 배포를 진행할 때 거의 대부분 github repository로만 배포하다보니까 다른 배포 방식은 어떻게 진행되는지 알아보고자 docker로도 배포를 해보았다.\n\n### Docker 배포 flow\n\n    1. Dockerfile을 통해 NodeJS 서버를 이미지로 변환\n    2. 생성된 이미지를 Docker Repository에 push\n    3. Docker Repository 주소를 사용하여 클라우드에 배포\n\nDocker로 배포하게 되면 위와같은 flow로 진행된다. Docker에 대한 기본적인 지식과 학습이 선행되어야 매끄럽게 진행될 것 같다.\n\n**[Dockerfile]**\n\n```\nFROM node:20\n\nWORKDIR \"/app\"\n\nCOPY ./package*.json ./\n\nRUN npm install\n\nCOPY . .\n\nEXPOSE 3000\n\nCMD [\"npm\", \"start\"]\n```\n\nDockerfile은 위와 같은 형태로 작성했다.\n\n이후, <code>docker build .</code> 명령어로 이미지를 빌드하고 나의 docker repository에 push하면 된다.\n\n![](https://velog.velcdn.com/images/eeeasy-code/post/63aa54f4-8afe-4719-884a-1d72ea448fc3/image.png)\n\n마지막으로 koyeb 배포 설정에서 docker-repository 주소를 입력 후 배포하면 된다.\n![](https://velog.velcdn.com/images/eeeasy-code/post/8147f915-c502-4a48-866a-7c37dd1ebd75/image.png)\n"},{"excerpt":"JWT란 무엇인가? JSON Web Token (JWT) 는 JSON 기반의 토큰으로, 정보를 안전하고 간결하게 주고받기 위한 기술입니다. JWT는 주로 인증(Authentication) 과 권한 부여(Authorization) 에 사용되며, HTTP 헤더, URI 쿼리 파라미터 등 공간이 제한된 환경에서도 쉽게 활용할 수 있습니다. 인증/인가를 위한 방…","fields":{"slug":"/TIL_04/"},"frontmatter":{"date":"December 02, 2024","title":"JWT란 무엇인가?","tags":["JWT","인증/인가"]},"rawMarkdownBody":"\n## JWT란 무엇인가?\n\n**JSON Web Token (JWT)** 는 JSON 기반의 토큰으로, 정보를 **안전하고 간결하게** 주고받기 위한 기술입니다. JWT는 주로 **인증(Authentication)** 과 **권한 부여(Authorization)** 에 사용되며, HTTP 헤더, URI 쿼리 파라미터 등 공간이 제한된 환경에서도 쉽게 활용할 수 있습니다.\n\n인증/인가를 위한 방식으로 다양한 선택지가 있지만, 매번 인증/인가를 위해 DB에 직접 연결(DB Connect)을 수행하면 성능 문제가 발생할 수 있습니다. 이를 해결하기 위해 서버가 사용자의 인증 상태를 유지할 수 있는 토큰 방식이 도입되었고, 그중 하나로 널리 사용되는 것이 JWT 방식의 인증/인가입니다.\n\n그럼 우리는 과연 JWT에 대해서 어느정도까지 알고 사용하고 있을까요?\n\n### JWT의 구조\n\nJWT는 세 가지 주요 부분으로 구성됩니다:\n\n1. **Header (헤더)**: 토큰의 메타데이터를 포함. (e.g., 서명 알고리즘, 타입)\n2. **Payload (페이로드)**: 전달할 데이터를 담고 있는 JSON 객체.\n3. **Signature (서명)**: 데이터의 무결성을 보장하기 위한 서명 값.\n\nJWT는 다음과 같은 형식으로 표현됩니다:\n\n```\nHeader.Payload.Signature\n```\n\n예시:\n\n```\neyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c\n```\n\n---\n\n## JWS와 JWE\n\nJWT는 크게 두 가지 형태로 사용됩니다: **JWS (JSON Web Signature)** 와 **JWE (JSON Web Encryption)**\n\n![JWS와 JWE](image.png)\n\n### JWS (JSON Web Signature)\n\nJWS는 JWT에 **디지털 서명**을 추가하여 **무결성을 보장**합니다.\n\n#### 특징\n\n- 데이터를 서명하여 **위변조 방지**를 보장.\n- 서명은 토큰을 발급한 서버만 확인할 수 있음.\n- 단, **데이터는 암호화되지 않으므로** 평문으로 노출될 수 있음.\n\n#### JWS 예제\n\n헤더와 페이로드를 서명한 결과:\n\n```\neyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwicm9sZSI6ImFkbWluIn0.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c\n```\n\n### JWE (JSON Web Encryption)\n\nJWE는 JWT를 **암호화**하여 **기밀성을 보장**합니다.\n\n#### 특징\n\n- 데이터를 암호화하여 **내용을 보호**.\n- 제3자가 데이터를 읽지 못하도록 보장.\n- 단, 암호화만 제공하므로 발급자가 신뢰할 수 있는지는 확인할 수 없음.\n\n#### JWE 예제\n\n암호화된 JWT는 다음과 같이 구성됩니다:\n\n```\neyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4R0NNIn0....\n```\n\n---\n\n## JWS와 JWE의 차이점\n\n| 특징               | JWS                       | JWE                  |\n| ------------------ | ------------------------- | -------------------- |\n| **기능**           | 무결성 보장 (위변조 방지) | 기밀성 보장 (암호화) |\n| **데이터 암호화**  | 암호화되지 않음           | 암호화됨             |\n| **주요 사용 목적** | 데이터의 신뢰성 확인      | 데이터의 내용 보호   |\n\n---\n\n## JWS와 JWE 결합\n\nJWS와 JWE를 결합하면 **기밀성과 무결성**을 모두 보장할 수 있습니다. 과정은 다음과 같습니다:\n\n1. **JWS 생성**: 데이터를 서명하여 무결성을 보장.\n2. **JWE 암호화**: 생성된 JWS를 암호화하여 기밀성을 추가.\n\n결과적으로 암호화된 데이터의 무결성까지 확인할 수 있는 안전한 토큰이 만들어집니다.\n\n---\n\n## JWT의 장점\n\n1. **간결성 (Compact)**:\n\n   - Base64URL로 인코딩되어 HTTP 헤더나 URI에서도 쉽게 사용 가능.\n\n2. **독립성 (Self-contained)**:\n\n   - 필요한 정보를 자체적으로 포함하므로 서버 측 세션 저장소가 불필요.\n\n3. **확장성 (Scalable)**:\n   - 표준 클레임과 커스텀 클레임을 조합하여 다양한 요구를 충족 가능.\n\n---\n\n## 보안 모범 사례\n\nJWT를 안전하게 사용하기 위해 다음을 권장합니다:\n\n1. **민감한 정보 저장 금지**:\n\n   - JWT는 디코딩이 쉬우므로 비밀번호와 같은 민감한 데이터는 저장하지 말 것.\n\n2. **HttpOnly 쿠키 사용**:\n\n   - XSS 공격을 방지하기 위해 브라우저에서 접근 불가능한 쿠키에 저장.\n\n3. **CSRF 방지**:\n\n   - 쿠키로 JWT를 사용할 경우 CSRF 방어를 반드시 적용.\n\n4. **강력한 키 사용**:\n\n   - 서명과 암호화를 위한 키는 충분히 길고 복잡해야 함.\n\n5. **짧은 만료 시간**:\n   - 토큰의 유효 기간을 짧게 설정하여 리스크를 최소화.\n\n---\n\n## 마무리\n\nJWT는 간결하고 강력한 인증 및 권한 부여 도구로, JWS와 JWE를 통해 다양한 보안 요구를 충족할 수 있습니다. 그러나 사용 목적에 맞는 적절한 구현과 보안 설정이 필요합니다. 이번 글에서 소개한 내용을 바탕으로 JWT를 더 안전하게 활용할 수 있길 바랍니다.\n\n궁금한 점이나 추가적인 논의가 필요하다면 댓글로 남겨주세요!\n"},{"excerpt":"언젠가 꼭 해보고 싶었던 컨텐츠를 이제부터 시작해보려고 합니다. 요즘 IT 서비스 기업이라면 대부분 테크 블로그를 운영하고 있습니다. 또한, 더 나아가 다양한 주제로 양질의 컨텐츠를 영상으로도 공개하고 있는데요. 저는 도입 검토를 진행 중이거나 적용해보고 싶은 혹은 새로운 기술들을 학습할 때, 이런 컨텐츠를 활용하고 있습니다. 정말 다양한 기업에서 특정 …","fields":{"slug":"/tech_review_01/"},"frontmatter":{"date":"December 02, 2024","title":"테크 컨텐츠 리뷰를 시작합니다.","tags":["테크 컨텐츠 리뷰","주니어 개발자","성장"]},"rawMarkdownBody":"\n언젠가 꼭 해보고 싶었던 컨텐츠를 이제부터 시작해보려고 합니다.\n\n요즘 IT 서비스 기업이라면 대부분 테크 블로그를 운영하고 있습니다. 또한, 더 나아가 다양한 주제로 양질의 컨텐츠를 영상으로도 공개하고 있는데요. 저는 도입 검토를 진행 중이거나 적용해보고 싶은 혹은 새로운 기술들을 학습할 때, 이런 컨텐츠를 활용하고 있습니다.\n\n정말 다양한 기업에서 특정 분야의 전문가 분들이 말하는 컨텐츠잖아요? 내부에서 컨텐츠를 공개하기까지 수많은 리뷰를 거쳤을 테고 검증된 자료인지 등의 평가도 이루어졌을 테니까요.\n\n그래서 저는 이런 컨텐츠들을 내가 해당 회사의 주니어 개발자고, 컨텐츠를 제공하는 매체를 제 사수라는 생각으로 접근합니다. 컨텐츠를 보며 떠오르는 아이디어, 궁금증 등을 잘 기록해서 해당 내용에 대해서 또 생각해보기도 하구요.\n\n특히, 저는 전 직장에 사수와 시니어 개발자가 없었고, 대부분 비슷한 연차의 주니어 개발자들로 구성된 조직에 있었습니다. 다양한 의사결정과 기술 도입 등에 대한 논의가 필요할 때, 저는 이런 컨텐츠들을 분석하고 이를 우리 서비스 관점에서 재정리해 공유했습니다. 이를 통해, 보다 더 신뢰있는 의견을 제시할 수 있었습니다.\n\n## 테크 컨텐츠의 장점\n\n### 거의 모든 컨텐츠가 무료\n\n일단 컨텐츠 자체가 대부분 무료인 것이 가장 큰 장점인 것 같습니다. 구체적인 구현을 공개하진 않지만, 설계 관점에서는 무료로 이만한 정보를 제공받는 것으로도 큰 도움이 되었습니다.\n\n### 조직의 가치관을 느낄 수 있음\n\n컨텐츠를 통해 해당 조직의 기술적인 깊이뿐만 아니라 그들이 기술을 바라보는 철학, 문제를 해결하는 방식, 그리고 사용자 경험을 얼마나 중시하는지 등의 가치관을 느낄 수 있었습니다. 이런 점은 단순히 기술적인 학습을 넘어, 서비스를 구현하기 위해 고려해야 할 시야를 넓혀주는 역할을 해줍니다.\n\n### 특정 기술 선택에 대한 명확한 근거\n\n테크 블로그나 영상에서는 특정 기술 스택을 왜 선택했는지, 해당 기술이 어떤 문제를 해결했는지에 대한 근거가 명확히 제시되는 경우가 많습니다. 이는 제가 비슷한 결정을 내릴 때 참고할 수 있는 귀중한 자료가 됩니다.\n\n## 컨텐츠 활용 방법\n\n저는 이 컨텐츠들을 단순히 소비하는 데 그치지 않고, 적극적으로 활용하려고 노력합니다.\n\n### 메모 및 아이디어 기록\n\n컨텐츠를 보면서 떠오르는 아이디어나 궁금증을 바로 기록합니다. 이를 통해 단순한 정보 소비에서 끝나지 않고, 개인적인 생각과 결합해 새로운 인사이트를 얻습니다.\n\n### 학습 계획에 반영\n\n컨텐츠에서 배운 내용을 실제로 적용해보고 싶을 때, 작은 프로젝트를 통해 실습하거나 학습 계획에 포함시킵니다. 이렇게 하면 단순히 \"알고 있는 것\"에서 \"할 수 있는 것\"으로 전환이 이루어집니다.\n\n### 동료와 공유\n\n좋은 컨텐츠를 발견하면 팀원들과 공유하여 서로 다른 관점에서 논의해보는 것도 큰 도움이 됩니다. 이를 통해 서로 다른 배경지식을 가진 사람들의 의견을 들으며 더 폭넓은 시야를 가질 수 있었습니다.\n\n## 마치며\n\n테크 컨텐츠는 단순한 정보 제공을 넘어, 개발자로서 성장할 수 있는 훌륭한 가이드가 될 수 있습니다. 무료로 제공되는 자료를 잘 활용하고, 이를 기반으로 스스로 사고하며 학습해 나간다면, 기술적인 깊이와 폭을 넓히는 데 큰 도움이 될 것입니다. 앞으로도 다양한 기업의 테크 컨텐츠를 리뷰하며 저만의 인사이트를 공유해보겠습니다.\n"},{"excerpt":"오늘은 일일 100만 건의 배송 데이터를 처리하고, 실시간 배송 상태를 고객에게 제공해야 하는 글로벌 물류 네트워크 관리 서비스를 설계할 때 고려해야 할 사항들을 설계해보았습니다. 특히 평균 TPS 70, 최대 TPS 300을 처리해야 하는 성능 요구사항이 존재합니다. 서비스 설계의 핵심 고려사항 확장성(Scalability): 수평 확장을 통해 부하에 …","fields":{"slug":"/TIL_03/"},"frontmatter":{"date":"November 27, 2024","title":"글로벌 물류 네트워크 백엔드 서비스 설계","tags":["아키텍처 설계"]},"rawMarkdownBody":"\n오늘은 일일 100만 건의 배송 데이터를 처리하고, 실시간 배송 상태를 고객에게 제공해야 하는 글로벌 물류 네트워크 관리 서비스를 설계할 때 고려해야 할 사항들을 설계해보았습니다. 특히 평균 TPS 70, 최대 TPS 300을 처리해야 하는 성능 요구사항이 존재합니다.\n\n## 서비스 설계의 핵심 고려사항\n\n- 확장성(Scalability): 수평 확장을 통해 부하에 따라 시스템을 유연하게 확장\n- 고가용성(High Availability): 장애 발생 시에도 서비스 중단 없이 운영될 수 있도록 이중화\n- 낮은 지연 시간: 실시간 배송 상태 제공을 위해 응답 속도 최적화\n- 데이터 일관성: 정확한 배송 정보를 제공하기 위한 데이터 일관성 유지\n- 보안: 고객 정보와 배송 데이터 보호를 위한 강화된 보안 조치\n\n## 데이터베이스 구조 및 기술 선택\n\nNoSQL 데이터베이스 채택 -> MongoDB나 Cassandra와 같은 NoSQL DB를 사용하여 수평 확장성과 높은 쓰기/읽기 처리량 확보\n\n- 데이터 모델링 최적화\n\n  - 비정규화를 통해 읽기 성능 향상\n  - 복합 인덱스와 지리 공간 인덱스로 빠른 데이터 조회\n\n- 샤딩(Sharding)과 파티셔닝(Partitioning)\n  - 샤딩 키로 배송 ID나 지역 정보를 사용하여 데이터 분산\n  - 파티셔닝을 통해 오래된 데이터와 최신 데이터를 분리 관리\n\n## 실시간 데이터 처리 아키텍처\n\n- 이벤트 드리븐 아키텍처를 도입하여 비동기식 데이터 처리\n- Apache Kafka를 사용한 고성능 메시징 시스템 구축\n\n- 실시간 스트리밍 처리\n\n  - Apache Flink나 Apache Spark Streaming을 활용하여 실시간 데이터 처리 및 분석\n\n- 데이터 파이프라인 최적화\n\n  - 백프레셔 관리, 체크포인팅, 효율적인 직렬화로 안정성과 성능 향상\n\n## 애플리케이션 성능 최적화\n\n- 비동기 논블로킹 I/O\n\n  - Spring WebFlux를 사용하여 높은 동시성 요청 처리\n  - NodeJS를 사용하여 싱글 스레드 논블로킹 I/O 처리\n\n- 효율적인 쓰레드 및 연결 관리\n\n  - ThreadPoolExecutor와 HikariCP로 자원 최적화\n\n- 캐싱 전략 적용\n\n  - Redis를 활용하여 자주 조회되는 데이터의 응답 시간 단축\n\n- JVM 튜닝\n  - 가비지 컬렉션 및 힙 메모리 설정 최적화로 지연 최소화\n\n## Java와 Node.js의 비교 및 선택\n\n### Java\n\n- 장점: 멀티쓰레딩 지원, 높은 성능, 풍부한 엔터프라이즈 솔루션 경험.\n- 적합성: 고성능과 안정성이 필요한 대규모 시스템에 적합.\n\n### Node.js\n\n- 장점: 비동기 I/O 모델, 빠른 개발 속도, 동일한 언어(JavaScript) 사용.\n- 적합성: 경량 애플리케이션이나 실시간 웹 서비스에 적합.\n\n### 결론\n\n본 서비스는 높은 성능과 안정성이 요구되므로 Java를 사용하는 것이 더 적합.\n\n## 모니터링 및 테스트\n\n- 부하 테스트\n\n  - Apache JMeter나 Gatling을 사용하여 TPS 목표치 검증\n\n- 모니터링 시스템 구축\n\n  - Prometheus와 Grafana로 시스템 메트릭 수집 및 시각화\n  - ELK Stack으로 로그 수집 및 분석\n\n## 추가 고려사항\n\n- 데이터 일관성 모델 선택\n\n  - **최종 일관성(Eventual Consistency)**을 채택하여 성능과 일관성의 균형 유지\n\n- 보안 강화\n\n  - OAuth 2.0이나 JWT를 사용한 인증 및 권한 부여\n  - SSL/TLS 암호화로 데이터 전송 보안 강화\n\n- 자동화 및 배포\n\n  - Docker와 Kubernetes로 컨테이너화 및 오케스트레이션\n  - CI/CD 파이프라인을 구축하여 지속적 통합 및 배포 자동화\n\n- 글로벌 서비스\n  - 글로벌 고객을 위한 다중 리전 or CDN 도입\n\n## 결론\n\n결론적으로, 글로벌 물류 네트워크 서비스를 설계할 때는 확장성과 실시간 처리 능력을 갖춘 아키텍처를 구축하는 것이 핵심입니다. 적절한 기술 스택과 성능 최적화를 통해 높은 TPS 요구사항을 충족하고, 고객에게 신뢰성 있는 실시간 배송 정보를 제공할 수 있습니다.\n"},{"excerpt":"Prerequisite : 본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다. kubernetes TLS istio 환경 저희 프로젝트는 이미 GKE 내에 istio 관련 설정이 기본적으로 셋팅되어 있습니다. Service Traffic GKE istio service mesh istio ingress gateway kiali 소개 서비스를 실…","fields":{"slug":"/k8s_tls_https/"},"frontmatter":{"date":"November 27, 2024","title":"k8s와 istio에 TLS 적용하기","tags":["MSA","istio","TLS","https"]},"rawMarkdownBody":"\n### Prerequisite :\n\n본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다.\n\n- kubernetes\n- TLS\n- istio\n\n### 환경\n\n저희 프로젝트는 이미 GKE 내에 istio 관련 설정이 기본적으로 셋팅되어 있습니다.\n\n![Service Traffic](<ezgif.com-video-to-gif-converter (1).gif>)\n\n- GKE\n- istio service mesh\n- istio ingress gateway\n- kiali\n\n## 소개\n\n서비스를 실제로 배포하고, 사용자들에게 더 안전한 서비스를 보장하기 위해 https 를 사용합니다.\n저희 프로젝트의 end-point는 istio ingress gateway로 연결되어 있습니다. 그렇기에 TLS 설정을 istio ingress gateway에 적용해야 합니다.\n\n## Cert Manager\n\ncert-manager는 kubernetes 클러스터에서 TLS 인증서의 관리를 자동화해 주는 오픈소스입니다. 이를 통해 인증서의 발급, 갱신 그리고 배포 과정을 자동화하여 보안을 강화하고 운영의 편의성을 높일 수 있습니다.\n\n![cert-manager](image-1.png)\n\ncert manager는 다양한 CA와 연동할 수 있는데, 저희 서비스 설정에서는 Let`s Encrypt를 사용했습니다.\n\n### 설정 과정\n\n#### install cert-manager\n\n<code> kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.1.0/cert-manager.yaml </code>\n\n해당 명령어를 통해 cert-manager를 설치합니다.\n\n저는 cert-manager-cainjector pod가 Kubernetes API 버전 호환성 문제로 인해 crash가 발생했는데, cert-manager의 버전을 v1.13.0 을 지정하여 설치했습니다.\n\n#### ClusterIssuer 리소스 생성\n\n```zsh\nkkubectl apply -f - <<EOF\n#prod\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod-istio\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: your email\n    privateKeySecretRef:\n      name: letsencrypt-prod-istio\n    solvers:\n    - http01:\n        ingress:\n          class: istio\n---\n#staging\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging-istio\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: your email\n    privateKeySecretRef:\n      name: letsencrypt-staging-istio\n    solvers:\n    - http01:\n        ingress:\n          class: istio\nEOF\nclusterissuer.cert-manager.io/letsencrypt-prod-istio created\nclusterissuer.cert-manager.io/letsencrypt-staging-istio created\n```\n\n이 설정은 cert-manager를 사용하여 Let`s Encrypt로부터 TLS 인증서를 발급하는 리소스를 생성합니다. 해당 설정을 통해 클러스터 내에서 자동으로 인증서를 발급받고 갱신할 수 있게 됩니다.\n\n> 두 개의 ClusterIssuer 리소스 생성\n>\n> - letsencrypt-prod-istio: Let’s Encrypt의 프로덕션 환경을 사용하여 실제 서비스에서 신뢰할 수 있는 인증서를 발급받기 위한 ClusterIssuer입니다.\n> - letsencrypt-staging-istio: Let’s Encrypt의 스테이징 환경을 사용하여 테스트 목적으로 인증서를 발급받기 위한 ClusterIssuer입니다. 이 환경에서 발급된 인증서는 브라우저에서 신뢰하지 않으며, 발급 제한 없이 테스트할 수 있습니다.\n\n> 설정의 목적과 역할\n>\n> 1. Let’s Encrypt와의 연동을 위한 ClusterIssuer 생성\n>    • cert-manager가 Let’s Encrypt를 통해 TLS 인증서를 발급받을 수 있도록 설정합니다.\n>    • 두 개의 ClusterIssuer를 생성하여 테스트 환경과 실제 서비스 환경에서 모두 인증서를 발급받을 수 있습니다.\n>\n> 2. ACME 프로토콜을 통한 인증서 발급 자동화\n>    • ACME(Automatic Certificate Management Environment) 프로토콜을 사용하여 도메인 소유권을 자동으로 검증하고 인증서를 발급받습니다.\n>    • cert-manager는 ACME 프로토콜을 구현하여 Let’s Encrypt와 통신합니다.\n>\n> 3. Istio Ingress Gateway와의 통합\n>    • ingress.class: istio 설정을 통해 HTTP-01 챌린지를 처리할 때 Istio Ingress Gateway를 사용하도록 지정합니다.\n>    • 이를 통해 도메인 검증 요청이 Istio Ingress Gateway를 통해 cert-manager로 전달됩니다.\n\n#### Certificate 리소스 생성\n\ncertificate.yaml 파일을 작성하여 원하는 도메인에 대한 TLS 인증서를 요청합니다.\n\n1. certificate.yaml 파일 작성\n\n```yaml\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: istio-ingressgateway-certs\n  namespace: istio-system\nspec:\n  secretName: istio-ingressgateway-certs\n  issuerRef:\n    name: letsencrypt-prod-istio # 이전에 생성한 ClusterIssuer 이름\n    kind: ClusterIssuer\n  commonName: your.domain.name # 실제 도메인 이름으로 변경\n  dnsNames:\n    - your.domain.name # 실제 도메인 이름으로 변경\n```\n\n2. certificate.yaml 파일 적용\n\n<code> kubectl apply -f certificate.yaml </code>\n\n이 명령어를 실행하여 Certificate 리소스를 클러스터에 적용합니다. cert-manager는 이 리소스를 감지하고, 지정된 ClusterIssuer를 통해 인증서를 발급받기 시작합니다.\n\n#### 인증서 발급 상태 확인\n\n<code> kubectl describe certificate istio-ingressgateway-certs -n istio-system </code>\n\n위의 명령어를 입력하게 되면 아래와 같은 정보가 나오게 됩니다.\n\n```zsh\nName:         istio-ingressgateway-certs\nNamespace:    istio-system\nLabels:       <none>\nAnnotations:  <none>\nAPI Version:  cert-manager.io/v1\nKind:         Certificate\nMetadata:\n  Creation Timestamp:  2024-11-26T13:48:49Z\n  Generation:          1\n  Resource Version:    1367115\n  UID:                 uuid\nSpec:\n  Common Name:  dns name\n  Dns Names:\n    dns name\n  Issuer Ref:\n    Kind:       ClusterIssuer\n    Name:       letsencrypt-prod-istio\n  Secret Name:  istio-ingressgateway-certs\nStatus:\n  Conditions:\n    Last Transition Time:  2024-11-26T14:08:12Z\n    Message:               Certificate is up to date and has not expired\n    Observed Generation:   1\n    Reason:                Ready\n    Status:                True\n    Type:                  Ready\n  Not After:               2025-02-24T13:09:40Z\n  Not Before:              2024-11-26T13:09:41Z\n  Renewal Time:            2025-01-25T13:09:40Z\n  Revision:                1\nEvents:                    <none>\n```\n\n전체적인 의미로는\n\n인증서 발급 상태\n\n    •\tReady 상태이며, 인증서가 정상적으로 발급되어 사용 중임을 나타냅니다.\n    •\tMessage에서 “Certificate is up to date and has not expired”라고 되어 있으므로, 인증서가 최신 상태입니다.\n\n인증서의 유효 기간\n\n    •\tNot Before: 2024-11-26T13:09:41Z\n    •\t인증서의 유효 시작일입니다.\n    •\tNot After: 2025-02-24T13:09:40Z\n    •\t인증서의 만료일로, 약 3개월의 유효 기간을 가집니다. Let’s Encrypt 인증서는 일반적으로 90일의 유효 기간을 갖습니다.\n    •\tRenewal Time: 2025-01-25T13:09:40Z\n    •\tcert-manager는 이 시점 전에 인증서를 자동으로 갱신합니다. 일반적으로 만료일의 30일 전에 갱신을 시작합니다.\n\n인증서의 발급자\n\n    •\tIssuer Ref에서 Kind가 ClusterIssuer이고 Name이 letsencrypt-prod-istio이므로, 이 인증서는 Let’s Encrypt 프로덕션 환경을 사용하여 발급되었습니다.\n\n인증서의 대상 도메인\n\n    •\tCommon Name과 DNS Names에 dns name이 설정되어 있습니다.\n    •\t이 인증서는 dns name 도메인에 대해 발급되었습니다.\n\n인증서의 저장 위치\n\n    •\t발급된 인증서와 개인 키는 istio-ingressgateway-certs라는 이름의 Secret에 저장됩니다.\n    •\t이 Secret은 istio-system 네임스페이스에 존재하며, Istio Ingress Gateway에서 참조하여 TLS 통신에 사용됩니다.\n\n## istio ingress gateway 설정\n\n여기까지 왔다면, Kubernetes 클러스터 내에서 자동으로 TLS 인증서를 관리하는 설정까지 완료했습니다.\n\n그 다음으로는 Istio Ingress Gateway에 인증서를 적용하고, HTTPS 설정을 진행해야 합니다. 이를 통해 외부에서 들어오는 트래픽에 대해 안전한 통신을 보장할 수 있습니다.\n\n### 설정 과정\n\n#### Istio Ingress Gateway에 인증서 적용\n\nIstio Ingress Gateway가 발급된 TLS 인증서를 사용하도록 설정하려면, 인증서가 저장된 Secret을 Gateway에 마운트해야 합니다.\n\n1.1 Istio Ingress Gateway 디플로이먼트 수정\n\n먼저, Istio Ingress Gateway의 Deployment를 수정하여 인증서 Secret을 마운트합니다.\n\n<code> kubectl edit deployment istio-ingressgateway -n istio-system </code>\n\n위 명령어를 실행하면 기본 에디터에서 Deployment의 YAML 파일이 열립니다. 여기서 다음과 같이 수정합니다.\n\nvolumes 섹션 추가\n\n```yaml\nspec:\ntemplate:\nspec:\nvolumes: - name: istio-ingressgateway-certs\nsecret:\nsecretName: istio-ingressgateway-certs\noptional: true\n```\n\nvolumeMounts 섹션 수정\n\ncontainers 섹션 아래의 volumeMounts에 다음 내용을 추가합니다.\n\n```yaml\ncontainers:\n  - name: istio-proxy # Istio Ingress Gateway의 컨테이너 이름입니다.\n    volumeMounts:\n      - mountPath: /etc/istio/ingressgateway-certs\n        name: istio-ingressgateway-certs\n        readOnly: true\n```\n\n전체 예시:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: istio-ingressgateway\n  namespace: istio-system\nspec:\n  selector:\n    matchLabels:\n      app: istio-ingressgateway\n  template:\n    metadata:\n      labels:\n        app: istio-ingressgateway\n    spec:\n      volumes:\n        - name: istio-ingressgateway-certs\n          secret:\n            secretName: istio-ingressgateway-certs\n            optional: true\n    containers:\n      - name: istio-proxy\n        volumeMounts:\n          - mountPath: /etc/istio/ingressgateway-certs\n            name: istio-ingressgateway-certs\n            readOnly: true # 나머지 설정들은 기존 내용 유지\n```\n\n변경 사항을 저장하면 Kubernetes는 Deployment의 변경을 감지하고 Istio Ingress Gateway 파드를 재시작하여 새로운 설정을 적용합니다.\n\n#### Istio Ingress Gateway 서비스의 포트 확인\n\nIstio Ingress Gateway 서비스에서 HTTPS를 위한 포트가 올바르게 설정되어 있는지 확인합니다.\n\n<code>kubectl get svc istio-ingressgateway -n istio-system</code>\n\n출력 결과에서 PORT(S) 열에 443 포트가 포함되어 있어야 합니다.\n\n예시:\n\n```zsh\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nistio-ingressgateway LoadBalancer 10.100.200.1 34.123.45.67 15021/TCP,80/TCP,443/TCP,15443/TCP,15012/TCP,15017/TCP 2d\n```\n\n만약 443 포트가 없거나 다른 포트로 설정되어 있다면, 다음과 같이 서비스의 설정을 수정합니다.\n\n<code>kubectl edit svc istio-ingressgateway -n istio-system</code>\n\nports 섹션에 다음 내용을 추가하거나 수정합니다.\n\nports:\n\n```yaml\n- name: https\n  port: 443\n  targetPort: 8443\n  protocol: TCP\n```\n\n#### Gateway 및 VirtualService 설정\n\n이제 Istio의 Gateway 및 VirtualService 리소스를 생성하여 Istio Ingress Gateway가 HTTPS 요청을 처리하고 적절한 서비스로 라우팅하도록 설정합니다.\n\nGateway 리소스 생성\n\ngateway.yaml 파일을 생성하고 다음과 같이 작성합니다.\n\n```yaml\napiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\nname: my-gateway\nnamespace: your-namespace # 실제 네임스페이스로 변경\nspec:\nselector:\nistio: ingressgateway # Istio Ingress Gateway를 선택\nservers:\n  - port:\n    number: 443\n    name: https\n    protocol: HTTPS\n    tls:\n    mode: SIMPLE\n    credentialName: istio-ingressgateway-certs # Secret의 이름과 일치해야 함\n    hosts:\n      - \"your.domain.com\" # 실제 도메인 이름으로 변경\n```\n\n적용하기:\n\n<code>kubectl apply -f gateway.yaml</code>\n\nVirtualService 리소스 생성\n\nvirtualservice.yaml 파일을 생성하고 다음과 같이 작성합니다.\n\n```yaml\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\nname: my-virtualservice\nnamespace: your-namespace # 실제 네임스페이스로 변경\nspec:\nhosts:\n\n- \"your.domain.com\" # 실제 도메인 이름으로 변경\n  gateways:\n- my-gateway\n  http:\n- match:\n  - uri:\n    prefix: \"/\" # 모든 요청 매칭\n    route:\n  - destination:\n    host: your-service # 실제 서비스의 이름으로 변경\n    port:\n    number: 80 # 서비스의 포트 번호로 변경\n```\n\n적용하기:\n\n<code>kubectl apply -f virtualservice.yaml</code>\n\n## DNS 설정 확인 및 업데이트\n\n도메인 이름이 Istio Ingress Gateway의 외부 IP 주소를 가리키도록 DNS 설정을 확인하고 필요하다면 업데이트합니다.\n\n### 설정 과정\n\n#### Istio Ingress Gateway의 외부 IP 확인\n\n<code>kubectl get svc istio-ingressgateway -n istio-system</code>\n\n출력 결과에서 EXTERNAL-IP 열에 표시된 IP 주소를 확인합니다.\n\n#### DNS 레코드 업데이트\n\nDNS 제공자의 관리 콘솔에서 해당 도메인의 A 레코드를 Istio Ingress Gateway의 외부 IP 주소로 설정합니다.\n\n#### HTTPS 연결 테스트\n\n설정이 완료되면 HTTPS 연결이 정상적으로 동작하는지 테스트합니다.\n\n```zsh\ncurl -vk https://your.domain.com\n```\n\n## 마무리\n\n이렇게해서 Istio Ingress Gateway에 TLS 인증서를 적용하고, HTTPS 설정을 진행해보았습니다. 이제 외부 클라이언트는 안전하게 HTTPS를 통해 서비스에 접근할 수 있습니다.\n\n추가적으로, 내부 서비스 간 통신에 대해 mTLS를 적용하여 클러스터 내 보안을 강화할 수도 있습니다.\n\n### 참고 자료\n\n[Istio 공식 문서 - TLS 설정](https://istio.io/latest/docs/tasks/traffic-management/ingress/secure-ingress/)\n\n[cert-manager 공식 문서](https://cert-manager.io/docs/)\n"},{"excerpt":"TL;DR 추상 vs 구체에 대해 실생활 예시를 통한 비교를 합니다. 추상 vs 구체 예시 CASE : 자동차 차를 운전하기 위해서 우리는 시동을 걸고, 기어를 D로 놓고 엑셀 페달을 밟으면 전진한다. 후진을 하기 위해서는 기어만 R로 변경하고 엑셀 페달을 밟는다. 멈추고 싶을 때 브레이크 페달을 밟는다. \n자동차 내부 구조 및 회로에 대해서 고민하고 알…","fields":{"slug":"/TIL_02/"},"frontmatter":{"date":"November 24, 2024","title":"추상과 구체","tags":["추상화","클린코드"]},"rawMarkdownBody":"\n### TL;DR\n\n추상 vs 구체에 대해 실생활 예시를 통한 비교를 합니다.\n\n<!-- # 추상 VS 구체\n\n## 추상화\n\n\n## 구체화 -->\n\n## 추상 vs 구체 예시\n\n### CASE : 자동차\n\n차를 운전하기 위해서 우리는 시동을 걸고, 기어를 D로 놓고 엑셀 페달을 밟으면 전진한다. 후진을 하기 위해서는 기어만 R로 변경하고 엑셀 페달을 밟는다. 멈추고 싶을 때 브레이크 페달을 밟는다. <br>\n자동차 내부 구조 및 회로에 대해서 고민하고 알아야 운전을 할 수 있는가?\n\n> **추상화** <br>\n\n- 시동을 건다.\n- 기어를 D로 놓고 엑셀 페달을 밟는다.\n- 기어를 R로 놓고 엑셀 페달을 밟는다.\n- 브레이크 페달을 밟는다.\n- ... 등등\n\n> **구체화** <br>\n\n- 시동을 걸면 배터리의 전력을 통해 엔진의 모터가 돌아간다.\n- 기어를 변경하면, 각 기어에 맞게 구동축을 이동시킨다. (각각의 기어 위치도 알아야겠지?)\n- 브레이크 페달을 밟으면, 유압이 올라가 ... 디스크를 잡아 마찰력을 높인다.\n- ... 등등\n\n![](https://i.imgur.com/argfrJ0.png)\n\n추상화 덕분에 우린 굉장히 편리하게 살아갈 수 있다.\n\n### CASE : 인프라 구성\n\n우리는 빠른 배포 환경을 구축하기 위해서 AWS 인프라를 사용한다. 손쉽게 Amazon EC2, AWS Lambda 등의 컴퓨팅 리소스를 빠르게 프로비저닝할 수 있다. <br>\n최근에 나는 추상화되어 있는 영역을 넘어 실제 구체를 다루기 위해, 홈서버를 구축했다. 왜 많은 사람들이 직접 구축하지 않는지를 알게되었다. <br>\n실제 물리적인 구성에 대한 고민을 해야하는가?\n\n> **추상화** <br>\n\n- Amazon EC2 메뉴에서 나에게 맞는 OS, 네트워크 설정을 간편하게 클릭하여 설정한다.\n- 이것마저 귀찮다면 AWS Lambda로 손쉽게 프로비저닝한다.\n- 그럼 알아서 어딘가 존재하는 HW로 서버가 만들어진다.\n- ... 등등\n\n> **구체화** <br>\n\n- 서버로 사용할 PC의 견적을 맞추고, 주문한 뒤 배송받고 설치한다.\n- VM 설정을 위해, 하이퍼바이저를 알맞게 (내 PC에 맞게) 설치하여 구성한다.\n- 인터넷에서 접근할 수 있도록 다양한 네트워크 설정을 해준다. (DDNS, 방화벽 등)\n- ... 등등\n\n![](https://i.imgur.com/BT34NLj.png)\n\n<!-- ## 그럼 추상화가 최고? -->\n"},{"excerpt":"NestJS @nestjs/microservices should handle RabbitMQ bindings and auto-generated queues 진행 이슈 link PR link 이슈 내용 nestjs 에서 제공하는 microservices 에서 RabbitMQ 를 사용할 경우, RMQ의 binding 과 auto-generated queues…","fields":{"slug":"/oss_project_03/"},"frontmatter":{"date":"November 16, 2024","title":"[NestJS] @nestjs/microservices should handle RabbitMQ bindings and auto-generated queues","tags":["오픈소스","NestJS"]},"rawMarkdownBody":"\n### [NestJS] @nestjs/microservices should handle RabbitMQ bindings and auto-generated queues\n\n- [진행 이슈 link](https://github.com/nestjs/nest/issues/13931)\n- [PR link](https://github.com/nestjs/nest/pull/14129)\n\n## 이슈 내용\n\nnestjs 에서 제공하는 microservices 에서 RabbitMQ 를 사용할 경우, RMQ의 binding 과 auto-generated queues 가 동작하지 않는 이슈\n\n![이슈 내용](image.png)\n\n## 해결 과정\n\n우선 제안한 해결 방안에 대한 가이드는 두 개로 다음과 같았습니다.\n\n1. The queues should be named in the expected format\n\n=> queue들은 예상된 형태로 이름이 부여되어야 함\n\n### 디버깅 포인트 1\n\n> queue의 이름이 ''로 지정될 때, RabbitMQ 의 옵션처럼 'amq.gen-asdnfks...' 형태가 아닌 'default'로 부여되는지를 파악\n\n우선 packages/microservices/constants.ts 에서 RQM_DEFAULT_QUEUE이 default로 지정되어 있었습니다. 그리고 queue 옵션이 ''로 넘어오면, queue에 RQM_DEFAULT_QUEUE이 할당되어 실제 queue name은 default로 할당되는 문제가 발생했습니다.\n\n단순히, packages/microservices/constants.ts 의 <code>export const RQM_DEFAULT_QUEUE = 'default';</code> 를 <code>export const RQM_DEFAULT_QUEUE = '';</code> 로 수정하니, 문제가 해결되었습니다.\n\n2. The binding should automatically happen\n\n=> binding은 자동적으로 진행되어야 함\n\n### 디버깅 포인트 2\n\n> binding 에 관련된 option들을 파악\n\n우선 binding 옵션은 exchange와 routingKey 인데, 실제 NestJS microservices의 rabbitMQ option에는 해당 값들이 존재하지 않았습니다. 그래서, RMQOption interface에 해당 값들을 optional로 추가해주었습니다.\n\nAS-IS\n\n```ts\n isGlobalPrefetchCount?: boolean;\n    queueOptions?: AmqplibQueueOptions;\n    socketOptions?: AmqpConnectionManagerSocketOptions;\n    noAck?: boolean;\n    consumerTag?: string;\n    serializer?: Serializer;\n```\n\nTO-BE\n\n```ts\n isGlobalPrefetchCount?: boolean;\n    queueOptions?: AmqplibQueueOptions;\n    socketOptions?: AmqpConnectionManagerSocketOptions;\n    // 해당 binding option을 optional로 추가\n    exchange?: string;\n    routingKey?: string;\n    noAck?: boolean;\n    consumerTag?: string;\n    serializer?: Serializer;\n```\n\n그 다음, 사용자가 지정한 binding option이 실제로 server에 적용되는 조건문이 존재하지 않았습니다. 그래서, client-rmq.ts 와 server-rmq.ts 에 해당 설정을 binding 해주는 로직을 추가했습니다.\n\nclient-rmq.ts\n\n```ts\nif (!this.noAssert) {\n  await channel.assertQueue(this.queue, this.queueOptions)\n}\n\n// 기존에 존재하지 않았던 로직\nif (this.options.exchange && this.options.routingKey) {\n  await channel.bindQueue(\n    this.queue,\n    this.options.exchange,\n    this.options.routingKey\n  )\n}\n\nawait channel.prefetch(prefetchCount, isGlobalPrefetchCount)\nawait this.consumeChannel(channel)\nresolve()\n```\n\nserver-rmq.ts\n\n```ts\n if (!this.noAssert) {\n      await channel.assertQueue(this.queue, this.queueOptions);\n    }\n\n// 기존에 존재하지 않았던 로직\nif (this.options.exchange && this.options.routingKey) {\n    await channel.assertExchange(this.options.exchange, 'topic', {\n    durable: true,\n    });\n    await channel.bindQueue(\n    this.queue,\n    this.options.exchange,\n    this.options.routingKey,\n    );\n}\n\nawait channel.prefetch(this.prefetchCount, this.isGlobalPrefetchCount);\nchannel.consume(\n    this.queue,\n```\n\n## 결과\n\n그 결과로 실제 local에서 RabbitMQ와 nestjs microservice 설정을 진행해보았는데, 제기되었던 이슈의 문제를 말끔하게 해결할 수 있게 되었습니다.\n\n![실제 테스트 결과](image-1.png)\n\nqueue를 ''으로 설정했을 때, Name이 'default'가 아닌 'amq.gen-...'으로 지정되었고, Binding의 option 또한 내가 지정한대로 잘 적용된 것을 확인할 수 있습니다.\n\n아직, merge되진 않았지만 다른 분께서 좋은 제안인 것 같다는 코멘트와 메인테이너 분께서 해당 이슈를 completed로 변경하신 뒤 milestone을 적용해주신 것으로 보아, 다음 milestone까지 해당 PR에서 추가 피드백이나 논의가 진행될 것으로 예상됩니다.\n\n- 2024.11.20 기준으로 드디어 nestjs 11 milestone에 PR이 merge 되었습니다~~~!\n\n![메인테이너가 직접 merge를 해주셨습니다~!](image-2.png)\n"},{"excerpt":"최근에 김인제 님께서 진행하시는 \"오픈 소스 멘토링 7기\" 활동을 진행했어요. 인제 님에 대한 소개는 깃허브 링크로 대신하겠습니다! 주변 지인의 추천으로 오픈 소스 멘토링을 소개받았었고, 지원자가 정말 많을 것이라는 이야기를 듣고 솔직히 멘토링에 선발될거라고 생각도 못했어요. 그런데 한 번에 되어버렸네요! ㅋㅋ  왜 오픈 소스를? 사실, 오픈 소스에 대한…","fields":{"slug":"/oss_project_01/"},"frontmatter":{"date":"November 16, 2024","title":"오픈 소스 기여: 작은 코드의 큰 가치","tags":["오픈소스","NestJS","오픈소스 멘토링"]},"rawMarkdownBody":"\n최근에 김인제 님께서 진행하시는 \"오픈 소스 멘토링 7기\" 활동을 진행했어요. 인제 님에 대한 소개는 [깃허브 링크](https://github.com/injae-kim)로 대신하겠습니다!\n\n주변 지인의 추천으로 오픈 소스 멘토링을 소개받았었고, 지원자가 정말 많을 것이라는 이야기를 듣고 솔직히 멘토링에 선발될거라고 생각도 못했어요. 그런데 한 번에 되어버렸네요! ㅋㅋ\n\n![](image.png)\n\n## 왜 오픈 소스를?\n\n사실, 오픈 소스에 대한 관심은 이전부터 있었고, 올해 첫 TOSS/AOP 라이브러리에 한글 문서 번역 기여를 진행했었어요. 물론 문서 번역이라는 간단한 기여였지만 제가 올린 PR이 merge되었을 때 정말 뿌듯했었죠.\n\n그럼 왜 오픈 소스 기여 활동을 하고 싶은 것이냐고 묻는다면, 아래의 내용으로 정리해볼 수 있을 것 같네요.\n\n### 1. 내가 사용하는 라이브러리 혹은 프레임워크를 운영하시는 메인테이너 분들의 가치관을 가장 직관적으로 알 수 있다.\n\n> 이게 무슨 말이냐면, 결국 기여하는 과정에서 메인테이너 분들의 리뷰를 받게 되어있는데 이 과정에서 그들이 어떠한 가치관을 갖고 해당 기술을 운영, 유지보수하는지 내 코드와 비교하며 대화를 나눌 수 있다는 것이죠.\n>\n> PR 뿐만 아니라 github에 올라온 Issue들을 잘 살펴보면, 메인테이너 분들이 의견을 공유해주시는데 이것도 그분들의 생각을 직관적으로 볼 수 있어요.\n>\n> 이를 통해서, \"해당 기술은 어떠한 방향성으로 사용해야 하는구나\" 와 같은 생각을 정리할 수 있었던 것 같아요. 그리고, PR이 merge가 되지 않거나, issue가 더 이상 논의되지 않아도 저는 충분히 가치가 있다고 생각해요. 그 과정에서 수많은 개발자들, 메인테이너들과 의견을 나누는 그 과정이 중요하다고 생각하거든요.\n\n![NestJS의 Member 분이 제안한 이슈](image-3.png)\n\n### 2. 내가 기여한 코드가 몇 년 후에는 수 억명의 개발자들이 사용하는 코드가 될 수 있다.\n\n> 이건 오픈 소스 멘토링을 진행하며 인제님께서 말씀해주셨던 내용인데요. 제가 앞으로도 오픈 소스 기여 활동을 꾸준히 해야겠다는 의지를 갖게 해준 말이었어요.\n>\n> 내 작은 코드 하나가 전 세계 개발자들에게 도달해 큰 가치를 줄 수 있다는 것 자체만으로도 오픈 소스에 기여할 충분한 동기가 되는 것 같아요. 그게 문서화 작업이라도, 누군가는 그 문서를 보고 도움을 받을 수 있으니까요!\n\n![어떤 분이 제 PR 내용을 보고 남긴 코멘트..!](image-1.png)\n\n### 3. 개발 스킬 외에도 문서화, 테스트 코드, 커뮤니케이션 스킬을 키울 수 있다.\n\n> 실제로 내 아이디어를 누군가에게 설명하고 납득시켜야 하는 과정이 필요해요. 내가 아무리 좋은 코드를 제안해도 (물론 너무 좋다면 approve가 되겠지만), 테스트 코드가 없어 검증하지 못하는 상황, 무슨 기능에 대한 내용인지에 대한 명확한 문서화가 없는 상황, 커뮤니케이션이 올바르게 되지 않아 지연되는 상황 등 기여에 대한 기회를 잃을 수 있는 문제들이 존재해요.\n>\n> 그래서, 좋은 코드를 작성하는 것도 중요하지만 내가 어떠한 문제를 파악했고, 이를 위한 개선점이 뭐가 존재하고 실제 구현 코드는 이렇다. 이에 대한, 검증은 이런 식으로 이루어졌다. 등 논리적으로 설명해 상대방을 납득시키는 것이 가장 중요한 점인 것 같아요.\n>\n> 또한, 대부분의 오픈 소스는 영어로 커뮤니케이션을 진행해야 하는데 내 생각을 영어로 정리해볼 수 있는 좋은 기회인 것 같아요. (저도 아직 번역기의 도움을 많이 받긴하지만) 글로벌 취업이 목표가 아니더라도 대부분의 공식 문서나 커뮤니티에서는 영어를 기본적으로 사용하기에 이런 스킬을 기르는 것도 강점이 될 것 같아요.\n\n![제가 제안한 내용에 대한 검증 과정을 설명하고 있어요.](image-2.png)\n\n이런 장점들이 저를 오픈 소스라는 생태계로 빠지게 만들어 준 것 같아요. 제가 작성한 내용 말고도 오픈 소스 활동은 정말 많은 장점이 존재하니까 꼭 시작했으면 좋겠어요.\n\n## 오픈 소스 멘토링?\n\nLine 백엔드 개발자로, 다양한 오픈 소스 활동을 하고 계신 김인제님께서 진행하는 '[오픈 소스 멘토링](https://medium.com/@injae-kim)'의 7기 과정에 참여했어요. 멘토링은 인제님이 먼저 가이드라인을 제시해주고 저희는 따라가기만 하면 되는 활동으로 진행되었어요.\n\n### 진행 과정\n\n1. 진행하고 싶은 issue 선정\n2. 선정한 issue에 대한 논의\n3. issue에 대한 PR 올리기\n4. 오픈소스 기부\n\n멘토링은 위의 과정대로 진행되었어요. 사실, 진행하면서 내가 아무것도 기여하지 못하면 어떻게 하지? 라는 걱정이 앞섰는데요. 그 이유는 이슈 선정부터 아무것도 못하겠다는 생각이 들었기 때문이에요. ㅋㅋㅋ 하나같이 이슈들은 개발 천재들이 올린 것 같고, 그 안에서 이야기하는 분들도 뭔가 범접하기 힘든 아우라가 있었거든요. 그래서, issue의 다양한 label들을 활용해서 그 중 가장 쉬워보이는 issue들을 몇 개 선정했어요.\n\nissue를 선정하고 나면, 인제님께서 각 issue에 대한 피드백을 꼼꼼하게 달아주시는데 정말 많은 참여자 분들의 이슈를 하나하나 작성해주시는 것보고 정말 너무 감사했습니다. 해당 피드백을 기반으로 내가 어떤 식으로 기여할지 가이드를 잡고, 멘토링이 있기 전까지 계속 그 issue들에 대해서 고민했어요.\n\n멘토링 당일에 인제님과 멘티분들이 한 자리에 모여 간단한 소개를 시작으로 각자 선정한 issue를 한번씩 훑어보는데요. 정말 다양한 분야의 오픈 소스를 선정하고 하나도 겹치지 않는 것을 보고 신기했습니다. 하나쯤은 겹치는 이슈가 있을까 걱정했었거든요.\n\n그렇게, issue에 대한 PR을 작성하면서 모르거나 막히는 부분이 있을 때, 인제님이 직접 피드백을 주시는데 이게 큰 도움이 되었던 것 같아요. 특정 기술에 대한 해결 방법보다, 어떤 식으로 오픈 소스에 접근하는지, 메인테이너 분들과 소통을 어떻게 해야하는지, 상대방을 설득하기 위해 어떤 식으로 PR을 작성해야 하는지 등 다양한 피드백을 주셨어요. (멘토링의 가장 큰 장점인 것 같았어요!)\n\n그 결과, 저는 NestJS에 대한 PR 2개, Spring Cloud에 대한 PR 1개를 작성해 기여할 수 있었습니다!!! 그리고, 멘토링의 관례?라고 해야할까요? 내가 원하는 오픈소스에 기부하는 활동이 있었는데, 저는 제가 기여한 NestJS에 기부를 진행했어요. 뭔가 내가 코드로도 기여하고, 직접 기부도 하니까 더 잘됐으면 좋겠다는 생각이 들더라구요. 좋은 경험이었던 것 같아요.\n\n## 마무리\n\n### 멘토링에서 느낀 점\n\n멘토링을 참가하면서 느낀 점은 크게 3가지로 정리할 수 있을 것 같아요.\n\n### 1. 오픈 소스 기여에 대해 무서워하지 말자. (PR 올리고, issue 만드는 거 쫄지말 것)\n\n> 처음에는 PR을 올릴지 말지, 인제님께 계속 물어봤어요. 이렇게 올려도 되는건가? 라는 걱정도 있었고, 누군가가 내 PR을 보고 좋지 않은 리뷰를 남기면 어떻게 하지? 라는 생각이 들었거든요. 근데 인제님꼐서 제가 올린 PR을 보고 이슈어나 메인테이너 분들은 좋아할 거라고, 걱정하지말고 PR 올려보라고 말씀해주셨어요. 사실, 어떻게보면 정답이 있는 것도 아니고 잘못된 부분이 있어도 그걸 굳이 비난할까? 싶더라구요. 그래서 PR을 올리고 issue를 만드는 것에 대해 걱정과 부담감을 내려놓고 마음껏 기여할 수 있게 된 계기가 된 것 같아요.\n\n### 2. 인내심을 갖자.\n\n> 메인테이너 분들도 똑같이 본업이 있고 오픈 소스 활동하는 일원이에요. 개인적으로 바쁠 수도 있고, 우선순위가 낮아질 수도 있는거죠. 또, 대부분 우리랑 시차가 맞지 않기떄문에 비동기 커뮤니케이션은 기본적인 것 같아요. 그래서 내가 올린 PR, issue에 그들의 반응이 늦어져도 그럴 수 있다는 생각을 갖고 하는 것이 중요한 것 같아요. 이 해답으로 하나의 issue말고 여러 개의 issue를 동시에 진행하는 것 ㅋㅋㅋ 이 있을 것 같아요!\n\n### 3. 고민할 시간에 뭐라도 기여해보자.\n\n> 이건 진짜 제가 계속 느낀 건데요. 아 이거 도전해볼까? 고민하는 찰나에 이미 다른 누군가가 기여해서 놓친 issue가 한두개가 아닌 것 같아요. 그냥 마음이 들었을 때, '내가 이 이슈에 대해서 기여해도 될까?' 혹은 PR을 만들어서 '내가 이 이슈에 대한 개선안을 코드로 구현해봤는데, 혹시 피드백 줄래?' 와 같이 바로 행동으로 옮기는 것이 속편해요. 거절당해도 좋은 경험이라 생각하면 되는 것이고, 피드백이 온다면 그것대로 또 얻는 것이 많으니까요.\n\n그리고, 마지막으로 내가 사용중인 기술에 대해 더 깊은 이해와 애정을 갖게 되는 계기였어요. 모두 오픈 소스 활동을 하기를 바라고, 저처럼 이 활동이 두려우신 분들은 인제님의 오픈소스 멘토링 활동에 참여해보는 것을 추천드립니다!!\n\n### 내가 기여한 것들\n\n마지막으로 제가 멘토링 진행하면서 기여한 것들을 공유할게요! 긴 글 읽어주셔서 감사합니다! :)\n\n### [NestJS] @nestjs/microservices should handle RabbitMQ bindings and auto-generated queues\n\n- [진행 이슈 link](https://github.com/nestjs/nest/issues/13931)\n- [PR link](https://github.com/nestjs/nest/pull/14129)\n- [해결 과정](https://eeeasycode.github.io/oss_project_03/)\n\n> NestJS의 createParamDecorator의 callback 으로 전달되는 context의 type이 현재 any로 추론되는 것을 ExecutionContext Type으로 지정하여 사용자들이 NestJS의 Docs를 참고하지 않아도 createParamDecorator를 사용할 수 있게 하면 좋을 것 같다는 내용의 이슈\n>\n> → NestJS Common 에 존재하는 custom-route-param-metadata.decorator.ts 파일을 수정하여 context의 type을 ExecutionContext로 명시하여 type 안정성 및 type 추론을 할 수 있도록 기여함\n\n### [NestJS] type narrowing context parameter on createParamDecorator's callback\n\n- [진행 이슈 link](https://github.com/nestjs/nest/issues/14093)\n- [PR link](https://github.com/nestjs/nest/pull/14126)\n- [해결 과정](https://eeeasycode.github.io/oss_project_02/)\n\n> nestjs 에서 제공하는 microservices 에서 RabbitMQ 를 사용할 경우, RMQ의 binding 과 auto-generated queues 가 동작하지 않는 이슈\n\n> → 1차 : 실제 원인 부분을 디버깅하여, 해당 문제에 대한 수정점을 코드로 제안하고 그 결과를 메인테이너 및 이슈어에게 제안함\n>\n> → 2차 : microservice의 RMQ 부분 로직에서 빠져있던, binding options을 추가하고 이를 queue에 binding 해주는 로직을 추가함. 또한, DEFAULT로 명시되던 queue name을 auto-generated 된 name으로 지정되도록 로직을 수정함. 이후, PR을 올려 메인테이너가 해당 이슈를 closed 한 뒤, 다음 마일스톤으로 할당함.\n\n### [Spring Cloud Gateway] [online-docs][4.1.5] 404 from link to properties\n\n- [진행 이슈 link](https://github.com/spring-cloud/spring-cloud-gateway/issues/3500)\n- [PR link](https://github.com/spring-cloud/spring-cloud-gateway/pull/3588)\n\n> Spring Cloud Docs의 잘못 명시된 link로 404 에러가 발생하는 이슈\n>\n> → 문제가 발생하는 부분 수정 후 PR 제안\n"},{"excerpt":"NestJS type narrowing context parameter on createParamDecorator's callback 진행 이슈 link PR link 이슈 내용  NestJS의 createParamDecorator의 callback 으로 전달되는 context의 type이 현재 any로 추론되는 것을 ExecutionContext Typ…","fields":{"slug":"/oss_project_02/"},"frontmatter":{"date":"November 16, 2024","title":"[NestJS] type narrowing context parameter on createParamDecorator's callback","tags":["오픈소스","NestJS"]},"rawMarkdownBody":"\n### [NestJS] type narrowing context parameter on createParamDecorator's callback\n\n- [진행 이슈 link](https://github.com/nestjs/nest/issues/14093)\n- [PR link](https://github.com/nestjs/nest/pull/14126)\n\n## 이슈 내용\n\n![메인테이너 분이 올린 issue 내용](image.png)\n\nNestJS의 createParamDecorator의 callback 으로 전달되는 context의 type이 현재 any로 추론되는 것을 ExecutionContext Type으로 지정하여 사용자들이 NestJS의 Docs를 참고하지 않아도 createParamDecorator를 사용할 수 있게 하면 좋을 것 같다는 내용의 이슈\n\n위의 사진에서 보이는 것처럼 현재 createParamDecorator의 parameter ctx type이 any로 지정되는 것을 볼 수 있다.\n\ncreateParamDecorator의 context 매개변수 타입이 any로 설정되어 있어, 타입 체크가 이 context의 구조나 내용에 대해 알려주지 못한다. 실제로는 ExecutionContextHost 인스턴스가 context로 전달되며, 이 인스턴스는 ExecutionContext 인터페이스를 구현한다. 타입을 ExecutionContext로 변경하면 코드 작성 시 올바른 타입 추론을 제공할 수 있다.\n\n## 해결 과정\n\n네, 작성하신 해결 방안을 순차적으로 설명드리겠습니다. createParamDecorator 함수의 context 매개변수 타입을 any에서 ExecutionContext로 좁히는 방안을 적용한 과정입니다.\n\n1. CustomParamFactory 인터페이스 수정\n\n먼저 CustomParamFactory 인터페이스에서 context 타입을 ExecutionContext로 변경하여 더 명확하게 정의했습니다.\n\n### 기존 코드\n\n기존 CustomParamFactory의 타입 정의에서는 context 매개변수 타입이 명확하지 않았습니다.\n\n```ts\nexport type CustomParamFactory<TData = any, TInput = any, TOutput = any> = (\n  data: TData,\n  input: TInput\n) => TOutput\n```\n\n### 수정된 코드\n\ncontext의 타입을 ExecutionContext로 지정하여, CustomParamFactory의 두 번째 매개변수가 ExecutionContext임을 명확히 하였습니다.\n\n```ts\nexport type CustomParamFactory<TData = any, TOutput = any> = (\n  data: TData,\n  context: ExecutionContext\n) => TOutput\n```\n\n이로 인해 CustomParamFactory를 사용하는 모든 곳에서 context가 ExecutionContext 타입을 가질 것임을 명확히 했습니다.\n\n2. createParamDecorator 함수 매개변수 타입 변경\n\n이제 createParamDecorator 함수에서 CustomParamFactory 인터페이스를 반영하여 context 매개변수를 ExecutionContext로 지정하였습니다.\n\n### 기존 코드\n\n기존 createParamDecorator의 factory 파라미터는 CustomParamFactory<FactoryData, FactoryInput, FactoryOutput>으로 정의되어 context의 타입이 명확하지 않았습니다.\n\n```ts\nexport function createParamDecorator<\nFactoryData = any,\nFactoryInput = any,\nFactoryOutput = any,\n\n(\nfactory: CustomParamFactory<FactoryData, FactoryInput, FactoryOutput>,\nenhancers: ParamDecoratorEnhancer[] = [],\n): (\n ...dataOrPipes: (Type<PipeTransform> | PipeTransform | FactoryData)[]\n) => ParameterDecorator {\n// function body\n}\n```\n\n### 수정된 코드\n\nCustomParamFactory 인터페이스를 수정하여 ExecutionContext 타입을 반영함으로써 createParamDecorator의 factory 매개변수도 ExecutionContext 타입을 받게 되었습니다.\n\n```ts\nexport function createParamDecorator<\nFactoryData = any,\nFactoryOutput = any,\n(\nfactory: CustomParamFactory<FactoryData, FactoryOutput>,\nenhancers: ParamDecoratorEnhancer[] = [],\n): (\n...dataOrPipes: (Type<PipeTransform> | PipeTransform | FactoryData)[]\n) => ParameterDecorator {\n// function body\n}\n```\n\n이를 통해 createParamDecorator가 ExecutionContext 타입의 context를 처리할 수 있도록 개선했습니다. 또한, context가 항상 ExecutionContext임을 보장할 수 있으며, 타입 안전성을 더욱 높였습니다.\n\n## 결과\n\nNestJS Common 에 존재하는 custom-route-param-metadata.decorator.ts 파일을 수정하여 context의 type을 ExecutionContext로 명시하여 type 안정성 및 type 추론을 할 수 있도록 기여했습니다.\n\n또한, ExecutionContext 타입을 더욱 명확히 하여 코드의 타입 안정성을 강화하고, 개발자가 NestJS의 문서를 참조하지 않아도 직관적인 코딩을 할 수 있게 개선했습니다.\n\n![메인테이너 분의 LGTM](image-1.png)\n"},{"excerpt":"Prerequisite : 본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다. 비동기/동기 Blocking/Non-Blocking Promise, async/await 첫 번째 NodeJS 스터디 주제는 \"싱글 스레드\" 입니다. Javascript를 접하면서 항상 들었던 말은 \"JS는 싱글 스레드 기반의 언어\" 라는 것인데요. 저는, 싱글 스레…","fields":{"slug":"/nodejs_study_01/"},"frontmatter":{"date":"November 12, 2024","title":"왜 NodeJS는 싱글 스레드인거지?","tags":["NodeJS"]},"rawMarkdownBody":"\n### Prerequisite :\n본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다.\n- 비동기/동기\n- Blocking/Non-Blocking\n- Promise, async/await\n\n첫 번째 NodeJS 스터디 주제는 \"싱글 스레드\" 입니다. Javascript를 접하면서 항상 들었던 말은 \"JS는 싱글 스레드 기반의 언어\" 라는 것인데요. 저는, 싱글 스레드 기반이라는 것을 그냥 아 그렇구나 하고 추가적인 학습을 하진 않았어요. \n\nNodeJS가 동작하는 방식을 이해하지 않은 채로 코드를 작성하다보니 왜 콜백 함수를 사용하는지, Promise나 async/await 를 사용하면 어떻게 처리되는지 이해하기가 더 어려워졌습니다. 그래서 이 주제를 선정해 학습을 진행했습니다.\n\n## NodeJS 특징\n\nNodeJS를 접한 사람이라면 특징에 대해서 정말 많이 이야기 들었을거에요.\n\n1. Single Thread 기반\n2. Event Driven 아키텍처\n3. Non-Blocking I/O 모델\n\n근데 여기서 한 가지 의문이 생기게 되었어요. 싱글 스레드 기반인데 어떻게 Non-Blocking I/O를 제공한다는 걸까요? 여기서 등장하는 것이 \"이벤트 루프\"입니다. \n\n### Event Loop\n\nEvent Loop 는 NodeJS의 가장 핵심 기능인데요. 일단, 우리가 NodeJS라는 녀석이 싱글 스레드라 불리는 이유는 이 이벤트루프가 메인스레드이면서 싱글스레드로 동작하기 때문입니다. \n\n![](https://i.imgur.com/OBzGOi7.png)\n\n_[출처]: [빨간색소년: nodejs의 내부 동작 원리](https://sjh836.tistory.com/149?source=post_page-----bb68434027a3--------------------------------)_\n\n실제로 위의 그림을 보면, libuv 라는 것 안에 이벤트루프가 존재하는 것을 볼 수 있습니다. NodeJS가 싱글 스레드이면서 Non-Blocking I/O를 제공할 수 있는 이유는 libuv 라는 라이브러리 덕분입니다.\n\n### libuv\n\nC언어 기반으로 작성된 라이브러리로, 비동기 I/O를 지원합니다. 커널의 비동기 API로 지원할 수 없는 작업을 비동기 처리할 수 있도록 별도의 Thread Pool을 가지고 있습니다.\n\n그럼 Thread Pool이 존재하는거니까 싱글 스레드가 아니지 않냐고 이야기할 수도 있지만, 아까 말했듯 NodeJS는 하나의 이벤트루프로만 동작을 합니다. 즉, 싱글 스레드로 이벤트루프가 동작하기 때문에, 싱글 스레드 기반인거죠.\n\n### 비동기 작업 처리 과정\n\n그럼 어떻게 비동기 작업들이 처리되는지 순서대로 확인해보겠습니다.\n\n1. 요청이 들어오면 Event Loop는 해당 요청이 Blocking I/O 작업인지를 판단\n2. 커널의 Non-Blocking I/O 지원을 받을 수 있는 작업이면 커널의 인터페이스로 해당 요청을 처리한 뒤, Event Queue에 해당 작업의 Callback을 등록\n3. 커널의 Non-Blocking I/O 지원을 받을 수 없는 작업이라면 libuv 내 존재하는 Thread Pool에서 Worker Thread를 선택해 해당 작업을 넘김. 이후, 작업이 완료되면 Event Queue로 해당 작업의 Callback을 등록\n4. Event Loop는 주기적으로 call stack이 비어있는지 확인 후 Event Queue에 실행 대기중인 Callback이 존재한다면 call stack으로 이동시켜 Main Thread에 의해 실행될 수 있게 함\n\n### 구체적인 예시\n\nlibuv의 역할을 이해하기 위해, 두 가지 예시로 살펴보겠습니다.\n\n\n1.\t파일 시스템 예시\n\n예를 들어, 파일을 읽어오는 작업을 수행한다고 가정해보겠습니다. 파일 시스템에 접근하여 데이터를 가져오는 작업은 시간이 걸릴 수 있으며, JavaScript 코드가 이 작업이 완료될 때까지 기다려야 한다면 비효율적입니다. 여기서 libuv가 개입하여, 메인 스레드가 기다리지 않고 다른 작업을 수행할 수 있도록 도와줍니다.\n\n\n>fs.readFile()을 호출하면, Node.js는 이 작업을 libuv로 전달합니다. libuv는 이 작업을 Thread Pool로 넘겨 처리하며, 이때 메인 스레드는 다른 작업을 계속 수행할 수 있습니다. 작업이 완료되면, libuv는 Event Queue에 콜백을 등록해, Event Loop가 그 콜백을 실행하도록 합니다.\n\t\n2.\t네트워크 요청 예시\n\n>HTTP 요청도 비슷하게 처리됩니다. 예를 들어, 외부 API 서버에 데이터를 요청하는 경우를 생각해보겠습니다. 일반적으로 네트워크 요청은 상대적으로 시간이 많이 걸리기 때문에, 요청을 보낸 후 그 응답을 기다리는 동안 메인 스레드가 중단된다면 다른 작업을 수행할 수 없습니다.\n>\n>네트워크 요청이 발생하면, libuv는 해당 요청을 비동기로 처리하여 응답을 기다리는 동안 메인 스레드가 다른 코드나 이벤트를 처리할 수 있게 합니다. 요청이 완료되면 마찬가지로 Event Queue에 콜백이 등록되어, Event Loop가 그 콜백을 실행합니다.\n\n이와 같은 방식으로, libuv는 파일 읽기, 네트워크 요청, 타이머 설정 등 다양한 비동기 작업을 Thread Pool 또는 OS의 비동기 API를 통해 처리합니다. 덕분에 Node.js는 싱글 스레드 기반임에도 효율적으로 비동기 작업을 수행할 수 있습니다.\n\n## 마무리하며\n\nNode.js의 비동기 처리 방식은 처음에는 복잡하게 느껴질 수 있지만, 핵심은 이벤트 루프와 libuv의 역할을 이해하는 것입니다. 이 두 가지 요소 덕분에 Node.js는 싱글 스레드의 한계를 극복하고, 높은 성능과 효율성을 제공하는 서버 환경을 구축할 수 있게 된거죠.\n\n우리는 왜 NodeJS가 싱글 스레드 기반이라고 불리는지 확실하게 이해했습니다. 더 나아가, 이를 활용해 적절한 비동기 처리를 통한 성능 향상이나 개선을 하며 코드를 작성할 수 있기를 바랍니다.\n "},{"excerpt":"최근에 진행하고 있는 프로젝트에서 저희는 마이크로 서비스 아키텍처를 도입했습니다. 기술 스택 선정에 있어서 우선 가장 자주 사용되는 기술들과 Cloud Native 환경에 적합한 기술들을 선정하기 위해 노력했습니다. 프로젝트에서 사용중인 기술 Spec K8s istio (Service mesh, Ingress Gateway) argoCD Prometheu…","fields":{"slug":"/istio-srping-cloud-gateway/"},"frontmatter":{"date":"November 11, 2024","title":"istio Ingress Gateway와 Spring Cloud Gateway 사용하기","tags":["MSA","Gateway","istio","Spring Cloud"]},"rawMarkdownBody":"\n최근에 진행하고 있는 프로젝트에서 저희는 마이크로 서비스 아키텍처를 도입했습니다. 기술 스택 선정에 있어서 우선 가장 자주 사용되는 기술들과 Cloud Native 환경에 적합한 기술들을 선정하기 위해 노력했습니다.\n\n### 프로젝트에서 사용중인 기술 Spec\n> - K8s\n> - istio (Service mesh, Ingress Gateway)\n> - argoCD\n> - Prometheus\n> - jaeger\n> - EFK\n\n또한, 내부 service들은 Knative로 구성된 NodeJS 기반 알림 서버를 제외하고 Spring 기반의 WAS로 운영되고 있습니다. 내부 service들은 service mesh로 구성되어 있고, 외부의 트래픽은 gateway를 통해 내부 service들로 접근하게 됩니다.\n간략히 그림으로 나타내면 다음과 같겠네요.\n\n![서비스 아키텍처](image.png)\n\n## Gateway \n\n일단, Gateway에 대해서 간략히 설명해보겠습니다. Gateway는 클라이언트와 서버 사이의 트래픽을 관리하고 요청을 적절한 서비스로 라우팅하는 역할을 합니다. 또한, 단일 진입점을 제공해 각 내부 서비스에서 공통으로 필요한 로직을 통합하여 처리할 수 있습니다. 인증/인가, 보안 정책, 유저 데이터 등을 처리한 뒤, 내부의 서비스로 라우팅해줍니다.\n\n저희 프로젝트에서는 Spring Cloud Gateway를 API 게이트웨이로, Istio Ingress Gateway를 인그레스 게이트웨이로 활용하는 구조를 택했습니다.\n\n실제 Kiali를 통해 볼 수 있는 저희 서비스의 gateway traffic 흐름은 다음과 같습니다.\n![kiali graph](image-1.png)\n\n## Istio Ingress Gateway 선택 이유\n\n![istio](image-3.png)\n\n사실, 저희 서비스에서 실제로 L4 트래픽을 관리할 일은 많지 않지만 기본적인 정책들을 적용해보고 싶었기 때문에 가장 앞단에 Ingress Gateway를 배치하게 되었습니다. 일단, Istio는 마이크로서비스 아키텍처에서 강력한 네트워크 관리와 트래픽 제어 기능을 제공하는 서비스 메시 솔루션인데요. 특히 Istio Ingress Gateway는 클러스터 외부로부터 들어오는 요청을 처리하고, 이를 적절한 내부 서비스로 라우팅하는 기능을 담당합니다. \n\n저희 서비스에서의 Istio Ingress Gateway는 클러스터 외부에서 들어오는 트래픽을 수신하고, 이를 내부로 전달하기 전에 초기 네트워크 정책을 적용하고 보안 설정을 적용합니다. 이를 통해 외부 트래픽에 대한 인증/인가, TLS 암호화 등을 처리하고 있습니다.\n\n## Spring Cloud Gateway 선택 이유\n\n![spring cloud](image-4.png)\n\napi-gateway와 연결된 서비스들이 Spring 기반의 WAS이기에 Spring 친화적으로 L7 트래픽에 대한 필터링과 라우팅을 제공하기 위해 선택했습니다. 다들 Spring Cloud Gateway에 대해서 잘 아실테니 설명은 따로 하지 않을게요.\n\n저희는 실제로, spring cloud의 api-gateway를 auth-service와 연결하여, 인증/인가 작업을 수행하며 적절한 라우팅 규칙을 통해 트래픽을 업스트림 서버로 전달합니다. 또한, 다양한 공통 작업들이 단일 지점에서 수행되는데요.\n\n1. 위에서 언급한 서비스에 대한 인증/인가\n2. request에 대한 전/후처리\n3. 다양한 공통 정보를 위한 필터링 로직 수행\n4. 안정적인 L7 통신을 위한 설정\n5. API 호출/응답 데이터 logging\n\n이 수행되고 있습니다.\n\n\n\n## 두 Gateway의 조합을 통한 이점\n\n1. 보안강화 \n\nIstio Ingress Gateway에서 외부 트래픽에 대한 초기 보안을 적용하고, Spring Cloud Gateway에서 추가적인 보안 로직을 처리함으로써 다중 보안 계층을 구축할 수 있습니다.\n\n2. 유연한 트래픽 관리\n\nIstio는 네트워크 레벨에서의 트래픽 제어를 담당하고, Spring Cloud Gateway는 애플리케이션 레벨에서의 세밀한 요청 처리를 담당하여 트래픽을 효율적으로 관리할 수 있습니다.\n\n3. 모니터링 및 관찰성 향상\n\nIstio의 분산 추적 기능과 Spring Cloud Gateway의 로깅 및 메트릭 수집 기능을 결합하여 클라이언트부터 내부 서비스까지의 트래픽 흐름을 종합적으로 모니터링할 수 있습니다.\n\n저희는 두 gateway의 조합을 통해 다양한 이점을 얻을 수 있게 되었고, 서비스의 안정성 또한 확보할 수 있었습니다.\n\n\n## 마지막으로\n\n이점이 많아보이지만, 이것도 결국 trade-off가 존재하겠죠. 초기 설정에 많은 시간을 할애했습니다. 특히, 두 개의 gateway에서 cors 관련된 이슈가 정말 추적하기 어려웠고 k8s 환경 자체도 실무에서 완전 cloud native한 환경을 구축해본 경험이 없었기에 삽질을 많이 했던 것 같습니다. 또한, 트래픽이 엄청나게 많지 않은 이상 gateway도 하나로 충분할 수 있었고, MSA 까지 가지 않아도 충분했을 겁니다. 그럼에도, 실험적인 도전은 이런 프로젝트가 아닌 이상 하기 힘들거라 판단했고, 직접 삽질하며 인프라 설계, 자동화, 서비스 로직 구현까지 뚝딱 해내고 있는 스스로를 보면 나쁘지만은 않은 것 같습니다. 이런 오버 엔지니어링도 스스로가 인지하고 있고, 마감일을 놓칠정도로 문제가 생기지 않으면 한번쯤 도전해볼만한 것 같아요.\n\n아래처럼 서비스가 안정적으로 동작하는 것만 봐도 뿌듯하네요.\n\n![나의 작고 소중한 서비스들](image-2.png)\n\n"},{"excerpt":"Prerequisite : 본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다. 객체 싱글톤 정적 팩토리 메서드 패턴 DI/IoC 최근에 프론트엔드 개발자 지인과 함께 커피챗을 했는데, \"객체\"와 \"싱글톤\" 에 관련된 주제로 이야기를 잠깐 나눴다. 정확히는 내가 정적 팩토리 메서드에 관한 이야기를 하다가 잘못 이야기를 한 부분이 있었는데, 정적 …","fields":{"slug":"/do_you_know_singleton/"},"frontmatter":{"date":"November 09, 2024","title":"싱글톤에 대한 오해","tags":["객체지향"]},"rawMarkdownBody":"\n### Prerequisite :\n본 글에서 언급되지만, 직접적인 설명은 하지 않는 것들입니다.\n- 객체\n- 싱글톤\n- 정적 팩토리 메서드 패턴\n- DI/IoC\n\n<hr>\n\n최근에 프론트엔드 개발자 지인과 함께 커피챗을 했는데, \"객체\"와 \"싱글톤\" 에 관련된 주제로 이야기를 잠깐 나눴다. 정확히는 내가 정적 팩토리 메서드에 관한 이야기를 하다가 잘못 이야기를 한 부분이 있었는데, 정적 팩토리 메서드 패턴으로 객체를 생성하면 객체들을 싱글톤으로 관리할 수 있다고 이야기를 했다.\n그리고, 그 자리에서 지인이 JS로 내가 말한 내용이 맞는지 바로 테스트했다. 그때 작성했던 코드는 다음과 같다.\n\n```javascript\nclass Latte {\n    constructor() {\n        return this.name = \"Latte\";\n    }\n}\n\nclass LatteFactory {\n    static makeCoffee() {\n        return new Latte();\n    }\n}\n\nconst factoryList = { LatteFactory };\n\nclass CoffeeFactory {\n    static makeCoffee(type) {\n        const factory = factoryList[type];\n\n        return factory.makeCoffee();\n    }\n}\n\nconst coffee = CoffeeFactory.makeCoffee(\"LatteFactory\");\nconst coffee2 = CoffeeFactory.makeCoffee(\"LatteFactory\");\n\nconsole.log(coffee==coffee2); // False\n```\n\n내가 말한대로라면, 정적 팩토리 메서드 패턴으로 생성된 두 객체는 싱글톤 객체니까, 비교했을 때 True가 나와야 했다. 근데, False가 나오게 되었다. 나는 '엥? 뭐지' 라고 생각을 했고, 그냥 서로 어찌저찌 이야기를 하다가 넘어가게 되었다.\n\n## 이걸 그냥 넘어간다고?\n커피챗이 끝나고 집으로 돌아가서 잠을 자려고 하는데, 아무리 생각해도 내가 뭔가를 잘못 설명한 기분이 들었다. 너무 찜찜한 기분이라 해결하고 자야겠다는 생각을 했다.\n\n다시 돌아가보자. 내가 분명 \"정적 팩토리 메서드 패턴을 사용하면, 객체는 싱글톤으로 관리돼\" 라고 이야기를 했다. 그래서, 다시 나누어 생각해보기로 한다.\n\n1. 정적 팩토리 메서드 패턴 -> 객체를 생성하는 디자인 패턴\n2. 싱글톤 객체 -> 객체의 인스턴스를 한개만 생성되게 하는 패턴\n\n### 정적 팩토리 메서드 패턴이 싱글톤을 보장하는가?\n당연하게도 정적 팩토리 메서드 패턴만을 사용한다고 객체가 싱글톤으로 생성된다는 것은 말이 안된다. 그 당시에 무슨 생각으로 그렇게 말을 했을까? 어쨌든, 정적 팩토리 메서드에 인스턴스가 싱글톤으로 생성될 수 있도록 검증하는 로직이 필요하다. 아까, JS로 테스트한 코드에 추가해보자.\n\n```javascript\nclass Latte {\n    constructor() {\n        return this.name = \"Latte\";\n    }\n}\n\nclass LatteFactory {\n    static makeCoffee() {\n        if (!LatteFactory.instance) {\n            LatteFactory.instance = new Latte();\n        }\n        return LatteFactory.instance;\n    }\n}\n\nconst factoryList = { LatteFactory };\n\nclass CoffeeFactory {\n    static makeCoffee(type) {\n        const factory = factoryList[type];\n\n        return factory.makeCoffee();\n    }\n}\n\nconst coffee = CoffeeFactory.makeCoffee(\"LatteFactory\");\nconst coffee2 = CoffeeFactory.makeCoffee(\"LatteFactory\");\n\nconsole.log(coffee==coffee2); // True\n```\n\nLatteFactory -> makeCoffee 메서드 내부에 해당 객체가 이미 존재하는지를 검증하는 로직이 추가되었다. 그 결과, 객체를 최초로 생성한 이후 추가 생성에 대해서는 새로 객체를 생성하지 않는다. \n\n이로써, 싱글톤 객체를 보장하는 정적 팩토리 메서드 패턴을 코드로 구현해보았다.\n\n지인에게 바로 연락해서 잘못된 내용을 바로 잡았다. \n![](https://i.imgur.com/zEDenOZ.png)\n\n## 근데 왜 잘못 말했지?\n\n지인에게 잘못된 내용에 대해 이야기하고 내가 왜 그렇게 생각했었는지 다시 고민해보았다. 우린, 객체 지향 프레임워크 (Spring, NestJS 등)을 사용하여 서비스를 구현한다. DI/IoC 기능으로 우리는 객체에 대한 생명 주기를 신경쓰지 않아도 되는데, 나는 이 부분과 혼동하여 무턱대고 \"정적 팩토리 메서드 패턴을 사용하면 객체가 싱글톤으로 관리됨\" 이라는 판단을 내린 것이다.\n\n## 그럼 객체 지향 프레임워크에서는 싱글톤을 어떻게 관리할까?\n\n갑자기, 객체 지향 프레임워크 내에서는 어떻게 객체를 싱글톤으로 관리하는지 궁금했다. 분명히, 내가 위에서 말한 싱글톤을 위한 검증 로직이 존재할텐데 어떤 식으로 구성을 하고 있는지 직접 두 눈으로 보고 싶다는 호기심이 생겼다.\n\n\n### NestJS Core부터 까보자\n\n우선, 내가 가장 잘 이해할 수 있는 NestJS 부터 까보기로 했다. 평소에도 NestJS의 Core를 뜯어봤기 때문에, 빠르게 확인할 수 있을 것 같았다. NestJS의 IoC 컨테이너를 바로 확인해봤다.\n\nNestJS에서 싱글톤 객체를 생성하고 관리하는 부분은 다음 메소드들에서 이루어진다:\n\n``` typescript\npublic async addModule(metatype: ModuleMetatype, scope: ModuleScope)\nprivate async setModule({ token, dynamicMetadata, type }: ModuleFactory, scope: ModuleScope)\npublic addProvider(provider: Provider, token: string, enhancerSubtype?: EnhancerSubtype)\n```\n\n여기서, addModule 메서드를 살펴보면,\n``` typescript\n// NestContainer.ts\n...\npublic async addModule(\n    metatype: ModuleMetatype,\n    scope: ModuleScope,\n  ): Promise<\n    | {\n        moduleRef: Module;\n        inserted: boolean;\n      }\n    | undefined\n  > {\n    // In DependenciesScanner#scanForModules we already check for undefined or invalid modules\n    // We still need to catch the edge-case of `forwardRef(() => undefined)`\n    if (!metatype) {\n      throw new UndefinedForwardRefException(scope);\n    }\n    const { type, dynamicMetadata, token } =\n      await this.moduleCompiler.compile(metatype);\n    if (this.modules.has(token)) {\n      return {\n        moduleRef: this.modules.get(token),\n        inserted: true,\n      };\n    }\n\n    return {\n      moduleRef: await this.setModule(\n        {\n          token,\n          type,\n          dynamicMetadata,\n        },\n        scope,\n      ),\n      inserted: true,\n    };\n  }\n    ...\n```\n\n위 코드에서 객체가 이미 생성되어 존재하는지를 확인하는 로직이 if 문으로 구현되어 있는 것을 확인할 수 있다. token은 모듈의 고유 식별자로, 각 모듈마다 유일한 token이 생성되며 중복 생성 방지에 중요한 역할을 한다.\n\n``` typescript\nif (this.modules.has(token)) {\n      return {\n        moduleRef: this.modules.get(token),\n        inserted: true,\n      };\n    }\n```\n\n이 코드에서는 모듈 token이 이미 존재할 경우 기존 모듈 인스턴스를 반환하여 싱글톤 패턴을 유지한다. 만약 존재하지 않는다면 setModule을 통해 새로 객체를 생성한다.\n\n``` typescript\nreturn {\n      moduleRef: await this.setModule(\n        {\n          token,\n          type,\n          dynamicMetadata,\n        },\n        scope,\n      ),\n      inserted: true,\n    };\n  }\n```\n\n이처럼, NestJS에서는 addModule 메소드 내 token 확인을 통해 싱글톤 패턴을 유지하고 있다.\n\n### Spring Core도 봐야지\n자 그럼, 최근에 내가 사용하고 있는 Spring에서도 동일한 기능을 어떻게 지원하는지를 확인해보자.\n\nSpring에서 싱글톤 객체 관리는 DefaultSingletonBeanRegistry 클래스의 getSingleton과 addSingleton 메서드를 통해 이루어진다. 이 과정에서 Spring은 싱글톤 패턴을 유지하기 위해 캐시 맵을 활용하며, 동일한 빈에 대한 중복 생성을 방지한다. 아래에서 Spring의 싱글톤 객체 관리 과정의 각 단계와 메서드를 설명한다.\n\ngetSingleton 메서드는 먼저 singletonObjects 캐시에 해당 빈이 존재하는지 확인한다. 빈이 이미 생성된 경우, 캐시에서 즉시 반환하여 불필요한 생성 과정을 피한다.\n\n```java\n// DefaultSingletonBeanRegistry.java\npublic Object getSingleton(String beanName, boolean allowEarlyReference) {\n    Object singletonObject = singletonObjects.get(beanName);\n    if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {\n        singletonObject = earlySingletonObjects.get(beanName);\n    }\n    ...\n    return singletonObject;\n}\n```\n\n이 메서드는 싱글톤 객체가 생성되지 않았다면, createBean 메서드를 호출해 객체를 생성하고 이를 캐시에 등록해준다. 이렇게 하면 동일한 빈에 대해 항상 같은 인스턴스를 반환하도록 보장한다.\n\n싱글톤 객체가 singletonObjects에 없으면, createBean 메서드가 호출되어 새 객체를 인스턴스화하고 의존성을 주입한 후 초기화 과정을 거친다. 생성된 객체는 addSingleton을 통해 캐시에 등록된다.\n\n```java\n// AbstractAutowireCapableBeanFactory.java\nprotected Object doCreateBean(String beanName, RootBeanDefinition mbd, Object[] args) {\n    BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args);\n    populateBean(beanName, mbd, instanceWrapper);\n    ...\n    return initializeBean(beanName, instanceWrapper.getWrappedInstance(), mbd);\n}\n```\nregisterSingleton 메서드도 외부 객체를 싱글톤으로 등록할 때 addSingleton을 호출한다.\n\n```java\n// DefaultSingletonBeanRegistry.java\npublic void registerSingleton(String beanName, Object singletonObject) {\n    ...\n    addSingleton(beanName, singletonObject);\n}\n\nprotected void addSingleton(String beanName, Object singletonObject) {\n    this.singletonObjects.put(beanName, singletonObject);\n    this.singletonFactories.remove(beanName);\n    this.earlySingletonObjects.remove(beanName);\n    this.registeredSingletons.add(beanName);\n}\n```\n\n이렇게 addSingleton은 빈을 싱글톤 객체로 캐시에 등록해, 이후 같은 빈 이름으로 요청이 들어오면 동일한 인스턴스를 반환하게 한다.\n\n## 마무리\n\n내가 잘못말한 내용이 프레임워크 코어까지 뜯어보게 한 트리거가 되었다. 궁금증이 생겼을 때 혹은 이해가 되지 않을 때 항상 끝까지 다이브하는 습관이 있는데, 나는 이 습관이 너무 잘 만들어 놓은 습관이라고 생각한다. 덕분에, 항상 새벽에 잠들긴하지만 몰랐던 부분에 대해서 그냥 넘어가는 것보다 훨씬 속편한 것 같다.\n\n아무튼, 이렇게 \"싱글톤에 대한 오해\" 로 시작해서, 실제 우리가 사용하고 있는 프레임워크 내부까지 살펴보았다. 앞으로는 어디가서 똑같은 실수를 하지 않아야겠다..^^"},{"excerpt":"TL;DR 간단하게 말해 모니터링과 옵저버빌리티는 진찰과 진단으로 분류할 수 있어요. 모니터링은 어디가 아픈지, 감기가 걸렸는지와 같은 상태를 확인하는 것이고 옵저버빌리티는 아픈 이유가 무엇인지 등에 대해 파악하는 것이라고 정리할 수 있겠네요. 단순히 정량적인 지표를 통한 상태 확인 뿐만 아니라 이 데이터들을 통합해서 원인을 파악하고 문제를 해결할 수 있…","fields":{"slug":"/msa-01/"},"frontmatter":{"date":"October 27, 2024","title":"모니터링 vs 옵저버빌리티","tags":["MSA","모니터링","옵저버빌리티"]},"rawMarkdownBody":"\n### TL;DR\n간단하게 말해 **모니터링**과 **옵저버빌리티**는 진찰과 진단으로 분류할 수 있어요. **모니터링**은 어디가 아픈지, 감기가 걸렸는지와 같은 상태를 확인하는 것이고 **옵저버빌리티**는 아픈 이유가 무엇인지 등에 대해 파악하는 것이라고 정리할 수 있겠네요. 단순히 정량적인 지표를 통한 상태 확인 뿐만 아니라 이 데이터들을 통합해서 원인을 파악하고 문제를 해결할 수 있게 하는 것이 중요해요.\n\n## 왜 모니터링과 옵저버빌리티가 필요할까?\n우리가 개발하는 서비스는 어떤 문제를 개선하고 해결하기 위해 존재합니다. 이런 서비스가 완벽하게 동작한다면 문제가 없겠지만, 우리의 서비스는 항상 장애나 문제에 노출되어 있습니다. 언제, 어디가, 어떻게 아플지 모르는 상황에서 이를 빠르게 해결해야 하는 책임이 생겼는데요. 이를 위해 탄생한게 **모니터링**과 **옵저버빌리티** 인거죠.\n\n## 그럼 모니터링과 옵저버빌리티는 무슨 차이가 있는걸까?\n\n![](https://i.imgur.com/m8ZbGEy.png)\n### 모니터링\n모니터링은 시스템에서 발생하는 이벤트를 실시간으로 감지하고 기록하며, 문제나 이상 행동이 발생했을 때 이를 알리는 역할을 합니다. 주로 미리 정해둔 임계치에 도달했을 때 알림을 보내주는 방식으로, **예상 가능한 상황**을 관리하는 데 유용합니다. 예를 들어 CPU 사용량이 80%를 넘거나 메모리 사용량이 특정 수준에 도달하면 경고 메시지를 보내주는 경우가 있죠.\n\n### 옵저버빌리티\n모니터링이 단순한 지표를 보고 문제를 알리는 데 중점을 둔다면, 옵저버빌리티는 이러한 지표들이 의미하는 바를 분석하여 문제의 근본 원인을 파악하는 것을 목표로 합니다. 복잡한 시스템에서는 예기치 못한 문제들이 발생할 가능성이 높기 때문에, 단순히 **'무엇이'** 발생했는지가 아니라 **'왜'** 발생했는지까지 파악하는 것이 중요합니다. 옵저버빌리티는 이렇게 복합적인 상황을 관찰하고 원인을 찾아 해결하도록 돕습니다.\n\n![](https://i.imgur.com/BbxyMBJ.png)\n\n### 각각의 구성 요소 차이\n모니터링은 시스템 상태의 즉각적인 감지와 경고에 중점을 두고, 옵저버빌리티는 문제의 근본 원인 파악과 분석에 초점을 맞춥니다. 이를 각 구성 요소를 통해 구체적으로 살펴보면 다음과 같은 차이가 있는데요.\n\n#### 모니터링의 구성 요소\n\n- 시스템 로그는 발생한 이벤트를 기록하여 문제가 언제, 어디서 발생했는지를 확인하는 데 도움을 줍니다.\n- 메트릭은 CPU, 메모리 사용량 등 현재 자원 상태를 수치로 나타내어 시스템 상태를 실시간으로 파악합니다.\n- 경고 및 알림 시스템은 설정된 임계치를 초과했을 때 담당자에게 경고를 보내어 빠르게 대응할 수 있도록 합니다.\n\n이 모든 요소는 현재 상태를 빠르게 파악하고 문제가 발생하면 즉시 알림을 주어 시스템 가용성을 유지하는 데 중점을 둡니다.\n\n![](https://i.imgur.com/fTCy7vA.png)\n\n#### 옵저버빌리티 구성 요소\n\n- 분산 트레이싱은 서비스 간 요청 흐름을 추적하여, 문제가 발생했을 때 해당 문제가 발생한 구체적인 서비스나 프로세스를 파악할 수 있습니다.\n- 로그 분석은 이벤트의 맥락을 이해하고, 어떤 상황에서 오류가 발생했는지 심층적으로 분석합니다.\n- 메트릭 상관관계 분석은 여러 메트릭 간의 관계를 살펴, 특정 이벤트가 여러 자원에 미치는 영향을 종합적으로 분석해 문제의 근본 원인을 찾습니다.\n\n옵저버빌리티 요소들은 주로 문제의 원인을 깊이 있게 분석하고, 예상치 못한 문제를 탐색하는 데 초점을 둡니다.\n\n![](https://i.imgur.com/YWWpY6O.png)\n\n\n## 근데 결국 같은 데이터를 활용하는거 아닌가?\n\n사실 위의 내용들로 모니터링과 옵저버빌리티의 차이를 이해하려고 했지만, 둘의 경계를 어떻게 나누어 이해하지? 라는 생각이 들었어요. 분명 차이점까지는 이해가 되었지만 데이터를 어떻게 활용하는지 구체적으로 이해할 필요가 있다고 생각했어요.\n\n### 공통적인 요소: 로그와 메트릭\n로그와 메트릭은 모니터링과 옵저버빌리티 모두에서 필수적인 데이터 소스인데요. 이 두 가지는 시스템의 이벤트나 상태를 수집하는 기본적인 방법으로, 두 개념이 시스템을 이해하는 데 핵심적인 역할을 했습니다.\n\n### 로그와 메트릭을 사용하는 방식의 차이\n**모니터링**에서는 로그와 메트릭을 주로 **상태 확인**과 **이상 탐지**에 사용합니다. 예를 들어, 메모리 사용량이 특정 임계치를 넘었을 때 경고 알림을 보내거나, 최근 로그에서 에러 코드가 많이 발생했을 때 이를 탐지하여 알려주는 방식이죠. 어디에서 문제가 발생했는지 알기 위해 실시간 수치와 상태를 간단하게 체크하는 데 사용됩니다.\n\n**옵저버빌리티**는 로그와 메트릭을 원인 파악과 상관관계 분석에 사용합니다. 단순히 상태를 감지하는 것을 넘어서, 왜 문제가 발생했는지를 분석하는 데 초점을 맞추죠. 예를 들어, 여러 서비스의 요청 흐름을 기록하여, 특정 요청이 어디에서 병목이 생겼는지 추적하거나, 로그와 메트릭을 종합해 서비스 간 상호작용을 분석해 문제의 근본 원인을 탐색합니다.\n\n## 왜 구성 요소로 나눠지는가?\n이렇게 나누는 이유는 모니터링과 옵저버빌리티가 로그와 메트릭을 어떻게 다루고, 어디에 목적을 두느냐에 따라 다른 데이터 구성과 접근 방법을 요구하기 때문이구나 라는 결론을 내렸습니다.\n\n모니터링에서는 실시간으로 상태를 단순히 감지하고 경고를 제공하는 시스템 구성이 중요한 반면,\n옵저버빌리티에서는 복잡한 서비스 구조에서 여러 데이터를 조합해 상호작용과 흐름을 이해하고, 예상치 못한 문제를 추적할 수 있는 시스템 구성이 필요합니다.\n\n그래서 같은 데이터라도 목적과 방식에 따라 각각의 기능을 구성 요소로 분리해 설명하는 것이였죠.\n\n## 안전한 시스템 환경을 위해 뭘 할 수 있지?\n\n모니터링과 옵저버빌리티를 통해 시스템 환경을 보다 안전하게 관리할 수 있어요.\n\n1. 장애 발생 시 더 빠른 대응과 원인 분석\n\n모니터링을 통해 빠르게 장애를 감지하고, 옵저버빌리티로 해당 장애의 근본 원인을 찾아 문제를 해결하는 데 걸리는 시간을 단축할 수 있습니다. 예를 들어, 특정 API 서비스에서 응답 시간이 급격히 늘어났다면 모니터링이 이를 감지해 경고를 보냅니다. 이후 옵저버빌리티가 해당 요청이 내부적으로 어떤 경로를 통해 처리되었는지, 각 서비스 간의 트레이싱을 분석해 병목 현상이 어디서 발생했는지를 명확하게 알려줍니다.\n\n2. 예상하지 못한 문제의 발견과 사전 예방\n\n모니터링은 주로 예상 가능한 이벤트나 임계치를 관리하는 반면, 옵저버빌리티는 복합적인 데이터 분석을 통해 예상치 못한 문제를 찾아내어 미리 대응할 수 있도록 합니다. 예를 들어, 트래픽 패턴이 변화하면서 서비스 성능에 영향을 줄 수 있는 지점을 사전에 파악해, 문제가 발생하기 전에 미리 최적화할 수 있습니다.\n\n3. 서비스 가용성과 안정성 향상\n\n모니터링과 옵저버빌리티를 함께 활용하면 시스템의 전반적인 가용성과 안정성을 높일 수 있습니다. 문제가 발생하더라도 그 영향이 확산되기 전에 감지하고, 정확한 원인 파악을 통해 빠르게 복구 조치를 취함으로써 서비스의 신뢰성을 유지할 수 있습니다. 이는 사용자의 경험을 보호하고, 비즈니스 연속성을 확보하는 데 큰 기여를 합니다.\n\n4. 팀 효율성과 문제 해결 능력 향상\n\n모니터링은 실시간 감지와 알림으로 운영팀이 문제가 발생했을 때 즉각적으로 대처할 수 있게 하며, 옵저버빌리티는 분석과 근본 원인 파악을 통해 운영팀의 문제 해결 능력을 높여 줍니다. 두 개념이 함께 사용되면, 단순히 장애에 대응하는 것을 넘어 지속적인 개선과 최적화로 이어질 수 있어 조직 전반의 운영 효율성이 향상됩니다.\n\n\n## 끝으로\n모니터링과 옵저버빌리티는 복잡한 시스템 환경에서 문제 발생 시 빠른 감지와 원인 파악을 통해 서비스 안정성을 높이는 핵심적인 역할을 합니다. 이 두 가지를 적절히 결합하여 사용하면, 서비스 운영에서 예기치 못한 문제를 사전에 예방하고, 장애 발생 시 신속하게 대응할 수 있어 운영 효율성을 크게 향상시킬 수 있습니다. \n\n다음 포스팅으로는 실제 제가 운영하고 있는 MSA 환경에서 모니터링과 옵저버빌리티를 도입해 어떤 이점을 가져올 수 있는지 등에 대한 이야기를 해보려고 합니다!\n"},{"excerpt":"살면서 회고를 많이 해보지 않았던 것 같다. 회사에서 월마다 했던 개발자로서의 회고말고 학습에 대한 회고는 특히 처음이다. \nYAPP 활동을 하면서 KPT 회고 채널에 기웃거린 적이 있어, KPT 회고에 대해서는 어느정도 알고 있었고, 지식 공유자 \"우빈\"님께서 추천한 템플릿에 때마침 KPT 회고가 있어 적용해보려 한다.  Keep (유지하고 싶은 점) …","fields":{"slug":"/2024_KPT_회고/"},"frontmatter":{"date":"October 06, 2024","title":"KPT 회고 첫 도전","tags":["클린코드","회고"]},"rawMarkdownBody":"\n살면서 회고를 많이 해보지 않았던 것 같다. 회사에서 월마다 했던 개발자로서의 회고말고 학습에 대한 회고는 특히 처음이다. <br>\nYAPP 활동을 하면서 KPT 회고 채널에 기웃거린 적이 있어, KPT 회고에 대해서는 어느정도 알고 있었고, 지식 공유자 \"우빈\"님께서 추천한 템플릿에 때마침 KPT 회고가 있어 적용해보려 한다.\n\n![지금 내 삶..](image.png)\n\n## Keep (유지하고 싶은 점)\n\n### 객체 지향 설계 원칙 학습의 중요성 \n강의에서 배운 SOLID 원칙과 객체 설계에 대한 이해가 프로젝트에서 큰 도움이 되었다. 특히, **SRP(단일 책임 원칙)**을 적용하여 클래스나 메서드를 단일 책임으로 분리하고, **OCP(개방-폐쇄 원칙)**에 따라 기존 코드를 수정하지 않고 확장할 수 있는 구조를 직접 설계해보며 학습.\n\n### 효율적인 시간 관리와 우선순위 설정\n졸업 프로젝트와 커뮤니티 활동을 병행하면서 효율적으로 시간을 분배한 덕분에 여러 활동을 동시에 진행할 수 있었다. 우선순위를 잘 설정하고, 중요한 작업에 집중하는 습관이 업무를 원활하게 마무리하는 데 큰 도움이 되었다.\n\n### 코드 가독성 향상\n강의에서 배운 내용을 통해 코드 가독성에 큰 개선을 이루었습니다. 메서드와 클래스의 추상화 레벨을 조정하여 복잡한 로직을 단순화하고, 이름 짓기 원칙을 준수하여 코드의 의미 전달력을 높이려고 노력했다.\n\n### 실제 프로젝트에 적용 \n강의 내용을 기반으로 실제 진행 중인 프로젝트에 적용해가며 이해하려고 노력하고 있다. 보다 더 생각을 많이하고 코드를 짜게 되는 것 같다.\n\n## Problem (아쉬웠던 점)\n\n### 프로젝트 제출 기한 관리 부족\n바쁜 스케줄로 인해 Day04 미션을 제출하지 못한 것이 너무 아쉽다. 여러 프로젝트와 커뮤니티 활동을 병행하는 과정에서 시간 관리가 어려웠고, 이를 통해 미션을 놓치게 된 점은 아쉬운 부분으로 남는다. 사실, 최고의 효율을 낼 수 있는 우선순위 설정을 했지만... 못한 부분이 있어 아숩다..\n\n### 시간 압박으로 인한 학습 부족\n프로젝트와 업무를 병행하다 보니, 일부 강의에서 다뤘던 디테일한 내용들을 직접 생각해보는 시간이 부족했다.\n\n## Try (다음 프로젝트에서 시도할 점)\n### 시간 관리 툴 도입\n프로젝트 제출 기한 관리를 위해 **타임 블로킹(Time Blocking)**이나 프로젝트 관리 툴(예: Notion, Trello)을 적극적으로 도입해볼 예정이다. 이러한 도구를 통해 일정과 우선순위를 보다 명확하게 관리하고, 놓치는 일이 없도록 해보자.\n\n### 이해한 내용들을 다시 글로 작성해보기\n조금 더 배운 내용들을 잘 정제해서 블로그 글로 포스팅해보려고 한다. 미션도 미션이지만, 나의 학습으로 완전한 지식으로 만들고자 한다."},{"excerpt":"NestJS에서의 DI와 인터페이스 SpringBoot 우선 SpringBoot에서 OCP와 DIP를 지키기 위해, DI하는 경우 인터페이스를 사용하는 것을 볼 수 있다. 간단하게, DI 받는 부분에서 private final UserService: userService 로 명시하는 것을 볼 수 있다. NestJS 그럼 NestJS도 SpringBoot와…","fields":{"slug":"/nestjs-interface-di/"},"frontmatter":{"date":"August 24, 2024","title":"NestJS에서 인터페이스 DI","tags":["NestJS"]},"rawMarkdownBody":"\n# NestJS에서의 DI와 인터페이스\n\n## SpringBoot\n\n우선 SpringBoot에서 OCP와 DIP를 지키기 위해, DI하는 경우 인터페이스를 사용하는 것을 볼 수 있다.\n\n```java\ninterface UserService {\n\tvoid signUp(..);\n}\n\n@Service\npublic class UserServiceImpl implements UserService {\n    @Override\n    public void signUp(..) {\n    \t...\n\t}\n}\n@RestController\npublic class UserController {\n\tprivate final UserService userService;\n        ...\n{\n```\n\n간단하게, DI 받는 부분에서 <code>private final UserService: userService</code> 로 명시하는 것을 볼 수 있다.\n\n\n## NestJS\n\n그럼 NestJS도 SpringBoot와 같은 개념이니까, 그대로 따라하면 정상적으로 동작할까?\n```ts\nexport interface UserService {\n    signUp(..);\n}\n\n@Injectable()\nexport class UserServiceImpl implements UserService {\n    signUp(..) {\n        ...\n    }\n}\n\n@Controller()\nexport class UserController {\n    constructor(\n        private readonly userService: UserService; \n    )\n    ...\n}\n```\n\n결과는  Nest can't resolve dependencies ~ 에러를 뱉어낸다. 의존성을 해결하지 못해 발생하는 에러인데, 왜 발생하는걸까? \n\n<br>\n\n### TS의 interface\nTypescript에서 제공하는 interface는 런타임 시 사라지게 된다. DI는 런타임 시점에서 동작하게 되는데, 해당 interface를 찾지 못해 의존성을 해결하지 못하는 것이다.\n\n그럼 그냥 사용하지 못하는걸까?\n\n<br>\n\n### Provider 설정\n\n그건 아니다. 다행히도 NestJS의 provider 설정을 직접 해주면 된다.\n\n```ts\n@Module({\n  controllers: [UserController],\n  providers: [\n    {\n      provide: 'USER_SERVICE',\n      useClass: UserServiceImpl,\n    },\n  ],\n})\nexport class UserModule {}\n\n@Controller()\nexport class UserController {\n    constructor(\n        @Inject('USER_SERVICE')\n        private readonly userService: UserService; \n    )\n    ...\n}\n```\n\n먼저, module의 providers에 Inject Token과 실제 구현 클래스를 명시해준다.\n그 뒤, DI 하는 부분에서 내가 명시한 Inject Token으로 Inject 받으면 문제 없이 인터페이스를 DI할 수 있게 된다.\n\n<br>\n\n# Reference\n[NestJS Providers](https://github.com/EeeasyCode/EeeasyCode.github.io/blob/main/contents/posts/nestjs-providers/index.md)\n"},{"excerpt":"Toss AOP 라이브러리 한글 문서 번역 왜 한글 문서 번역? 최근에 오픈소스 기여에 대해 관심이 생기고 바로 내가 기여할 수 있는 게 무엇일까를 고민하던 중, 어떤 블로그에서 영어 문서를 한글 문서로 번역하는 것부터 시작해보라는 말을 보게 되었다. 그래서, 내가 최근 가장 관심있게 보던 오픈소스인 TOSS의 AOP 라이브러리를 확인해보았고, 마침 영어…","fields":{"slug":"/opensource-toss-aop/"},"frontmatter":{"date":"June 20, 2024","title":"Toss AOP 라이브러리 한글 문서 번역 기여","tags":["오픈소스","NestJS"]},"rawMarkdownBody":"\n# [Toss AOP 라이브러리] 한글 문서 번역\n\n## 왜 한글 문서 번역?\n\n최근에 오픈소스 기여에 대해 관심이 생기고 바로 내가 기여할 수 있는 게 무엇일까를 고민하던 중, 어떤 블로그에서 영어 문서를 한글 문서로 번역하는 것부터 시작해보라는 말을 보게 되었다.\n\n그래서, 내가 최근 가장 관심있게 보던 오픈소스인 TOSS의 AOP 라이브러리를 확인해보았고, 마침 영어 문서 밖에 없어 한글 문서 번역을 기여했다.\n\n어려운 내용은 크게 없었고, 내가 기여한 번역을 통해 누군가는 도움이 되었으면 하는 마음으로 진행했다.\n\n## 기여한 내용\n\nToss의 NodeJS Developer 챕터에서 만든 라이브러리의 사용 예제에 대해 문서 번역을 기여했다.\n\n## 느낀 점\n\n오픈소스 기여라고 하면 굉장히 어려운 것처럼 다가오는 것 같다. 사실은 한글 문서 번역도 나름이지만 어쨌든 누군가에게 편리함을 줄 수 있는 것에 대해 도움이 될 수 있다면 그것도 나는 기여했다고 생각한다.\n\n다음으로 TOSS/AOP 라이브러리가 무엇인지 자세히 분석해보려고 한다.\n\n<!-- [TOSS/AOP 라이브러리 분석](https://eeeasycode.github.io/toss-aop-review/) -->\n\n## Reference\n\n[기여한 PR Link](https://github.com/toss/nestjs-aop/pull/35 \"toss-github link\")\n"},{"excerpt":"Feature 빌드 속도를 개선하기 위해, yarn classic -> yarn berry (zero install) -> pnpm으로 마이그레이션 하는 과정과 docker multi-stage 적용, nestjs에서 swc를 통한 컴파일 속도 최적화를 진행했습니다. Situation 현재 저희는 AWS ECS를 통해 서버를 배포하고 있습니다. githu…","fields":{"slug":"/nestjs-build-time/"},"frontmatter":{"date":"June 18, 2024","title":"NestJS 빌드 속도 개선","tags":["NestJS","package manager","성능개선"]},"rawMarkdownBody":"\n# Feature\n\n빌드 속도를 개선하기 위해, **yarn classic -> yarn berry (zero install) -> pnpm**으로 마이그레이션 하는 과정과 **docker multi-stage** 적용, nestjs에서 **swc**를 통한 컴파일 속도 최적화를 진행했습니다.\n\n## Situation\n\n현재 저희는 **AWS ECS**를 통해 서버를 배포하고 있습니다. github의 코드가 **docker image**로 빌드되고, **AWS ECR**을 거쳐 **AWS ECS**의 인스턴스로 생성되는 파이프라인이 구성되어 있습니다.\n\n## Task\n\n- package 설치 속도 및 의존성 관리 개선\n- docker 빌드 속도 개선\n- nestjs 빌드 · 컴파일 속도 개선\n\n## Action\n\n### package manager 마이그레이션\n\n기존 yarn classic에서 yarn berry (zero-install)을 업그레이드한 뒤, 다양한 고려사항으로 인해 pnpm으로 최종 마이그레이션을 진행했습니다.\n\n실제 pacakge 설치 속도 및 크기를 크게 개선할 수 있었습니다.\n| yarn classic | pnpm |\n| ---------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n| 153.4s | 49.0s |\n\n> package manager 마이그레이션 과정은 해당 포스팅에서 확인할 수 있습니다.\n\n### docker multi-stage 적용\n\n### nestjs에서 swc 적용\n\n## Result\n\n해당 작업 결과로 docker 이미지 빌드 시간은 301.6s -> 112.6s 로 개선했고,\n이미지 용량도 1GB -> 830MB로 감소시킬 수 있었다.\n| yarn classic | pnpm |\n| ------------------------------------ | ------------------------------------ |\n| [+] Building 301.6s (12/12) FINISHED | [+] Building 112.6s (17/17) FINISHED |\n\n<img width=\"1157\" alt=\"upload_test\" src=\"https://imgur.com/zJUQ9n9.png\">\n"},{"excerpt":"Feature typeORM에서 연관관계가 없는 테이블 간 join 하는 방법 Tables User 테이블 Payment 테이블 각 테이블은 연관관계를 설정하지 않았고, payment 테이블에서 userId를 저장할 수 있게 했습니다. Join case 모든 user에 대한 payment 정보를 조회하기 위해 join을 합니다. 동작한 query 리턴된 …","fields":{"slug":"/typeorm-join/"},"frontmatter":{"date":"May 12, 2024","title":"연관관계 없이 join","tags":["nestjs","typeorm","database"]},"rawMarkdownBody":"\n# Feature\n\ntypeORM에서 연관관계가 없는 테이블 간 join 하는 방법\n\n## Tables\n\n### User 테이블\n\n<img width=\"1166\" alt=\"user_table\" src=\"https://velog.velcdn.com/images/eeeasy-code/post/50634c0e-0673-416b-89b1-c59c4ddbe95e/image.png\">\n\n### Payment 테이블\n<img width=\"1179\" alt=\"payment_table\" src=\"https://velog.velcdn.com/images/eeeasy-code/post/4e82823e-3179-49b2-8f71-561a9944d7c5/image.png\">\n\n각 테이블은 연관관계를 설정하지 않았고, payment 테이블에서 userId를 저장할 수 있게 했습니다.\n\n## Join case\n\n모든 user에 대한 payment 정보를 조회하기 위해 join을 합니다.\n\n```typescript\nasync leftJoin() {\n    return await this.usersRepository\n      .createQueryBuilder('user')\n      .leftJoinAndMapMany('user.payment', Payments, 'payment', 'user.id = payment.userId')\n      .getMany();\n}\n```\n\n### 동작한 query\n\n```shell\nquery: SELECT `user`.`id` AS `user_id`, `user`.`userEmail` AS `user_userEmail`, `user`.`password` AS `user_password`, `user`.`created_at` AS `user_created_at`, `user`.`updated_at` AS `user_updated_at`, `user`.`deleted_at` AS `user_deleted_at`, `payment`.`id` AS `payment_id`, `payment`.`userId` AS `payment_userId`, `payment`.`created_at` AS `payment_created_at`, `payment`.`updated_at` AS `payment_updated_at`, `payment`.`deleted_at` AS `payment_deleted_at` FROM `users` `user` LEFT JOIN `payments` `payment` ON  `user`.`id` = `payment`.`userId` AND `payment`.`deleted_at` IS NULL WHERE `user`.`deleted_at` IS NULL\n```\n\n### 리턴된 결과값\n\n```json\n[\n  {\n    \"id\": 1,\n    \"userEmail\": \"user1@example.com\",\n    \"password\": \"password123\",\n    \"created_at\": \"2024-05-06T16:08:37.000Z\",\n    \"updated_at\": \"2024-05-06T16:08:37.000Z\",\n    \"deleted_at\": null,\n    \"payment\": [\n      {\n        \"id\": 4,\n        \"userId\": 1,\n        \"created_at\": \"2024-05-06T16:10:18.000Z\",\n        \"updated_at\": \"2024-05-06T16:10:18.000Z\",\n        \"deleted_at\": null\n      },\n      {\n        \"id\": 1,\n        \"userId\": 1,\n        \"created_at\": \"2024-05-06T16:10:18.000Z\",\n        \"updated_at\": \"2024-05-06T16:10:18.000Z\",\n        \"deleted_at\": null\n      }\n    ]\n  },\n  {\n    \"id\": 2,\n    \"userEmail\": \"user2@example.com\",\n    \"password\": \"password123\",\n    \"created_at\": \"2024-05-06T16:08:37.000Z\",\n    \"updated_at\": \"2024-05-06T16:08:37.000Z\",\n    \"deleted_at\": null,\n    \"payment\": [\n      {\n        \"id\": 3,\n        \"userId\": 2,\n        \"created_at\": \"2024-05-06T16:10:18.000Z\",\n        \"updated_at\": \"2024-05-06T16:10:18.000Z\",\n        \"deleted_at\": null\n      },\n      {\n        \"id\": 2,\n        \"userId\": 2,\n        \"created_at\": \"2024-05-06T16:10:18.000Z\",\n        \"updated_at\": \"2024-05-06T16:10:18.000Z\",\n        \"deleted_at\": null\n      }\n    ]\n  },\n  {\n    \"id\": 3,\n    \"userEmail\": \"user3@example.com\",\n    \"password\": \"password123\",\n    \"created_at\": \"2024-05-06T16:08:37.000Z\",\n    \"updated_at\": \"2024-05-06T16:08:37.000Z\",\n    \"deleted_at\": null,\n    \"payment\": [\n      {\n        \"id\": 5,\n        \"userId\": 3,\n        \"created_at\": \"2024-05-06T16:10:18.000Z\",\n        \"updated_at\": \"2024-05-06T16:10:18.000Z\",\n        \"deleted_at\": null\n      }\n    ]\n  },\n  {\n    \"id\": 4,\n    \"userEmail\": \"user4@example.com\",\n    \"password\": \"password123\",\n    \"created_at\": \"2024-05-06T16:08:37.000Z\",\n    \"updated_at\": \"2024-05-06T16:08:37.000Z\",\n    \"deleted_at\": null,\n    \"payment\": []\n  },\n  {\n    \"id\": 5,\n    \"userEmail\": \"user5@example.com\",\n    \"password\": \"password123\",\n    \"created_at\": \"2024-05-06T16:08:37.000Z\",\n    \"updated_at\": \"2024-05-06T16:08:37.000Z\",\n    \"deleted_at\": null,\n    \"payment\": []\n  }\n]\n```\n"},{"excerpt":"Feature Image Upload 서버에서 Sharp 라이브러리를 사용해 Content-type 변경하는 기능 구현 Situation 기존 운영중인 서비스은 S3에 이미지 업로드 할 때, image/jpg로 업로드됩니다.\nJPG는 PNG에 비해 작은 용량의 크기로 사진을 압축할 수 있지만 WebP와 비교했을 때 화질면에서 크게 떨어집니다.\n또한, We…","fields":{"slug":"/nestjs-image-upload/"},"frontmatter":{"date":"April 03, 2024","title":"이미지 업로드 성능 개선","tags":["NestJS","성능개선"]},"rawMarkdownBody":"\n# Feature\n\nImage Upload 서버에서 Sharp 라이브러리를 사용해 Content-type 변경하는 기능 구현\n\n## Situation\n\n기존 운영중인 서비스은 S3에 이미지 업로드 할 때, image/jpg로 업로드됩니다.\nJPG는 PNG에 비해 작은 용량의 크기로 사진을 압축할 수 있지만 WebP와 비교했을 때 화질면에서 크게 떨어집니다.\n또한, Webp는 PNG에 비해 크기가 26%, JPEG 이미지보다 25~34% 더 작습니다.\n\n> 출처 : https://developers.google.com/speed/webp?hl=ko\n\n## Task\n\n- 업로드 할 이미지의 용량 축소 기능 구현\n- Sharp 라이브러리를 활용하여 이미지의 Content-Type을 image/webp 로 변환\n\n## Action\n\n- 이미지 업로드 API의 서비스 로직에 Sharp 라이브러리로 Image의 Buffer를 webp로 변환\n- 이미지 파일의 확장자를 .webp로 변환\n- S3 업로드 시, ContentType을 image/webp로 설정\n\n## Result\n\n테스트 결과 -> 파일 A, 파일 B\n\n> png 파일 업로드 -> 131.2 KB, 333.5 KB <br>\n> jpeg 파일 업로드 -> 86.0 KB, 241.8 KB <br> > **webp 파일 업로드 -> 50.9 KB, 128.2 KB** <br>\n\n로 webp 변환 시 저장 공간에 대한 효율성을 향상시킬 수 있습니다.\n이는 업로드에 대한 성능 뿐만 아니라, 실제 클라이언트에게 이미지 파일이 전달될 때에 확실한 성능 차이가 보여질 것으로 판단됩니다.\n\n![](https://velog.velcdn.com/images/eeeasy-code/post/f8753929-ab0b-40a9-abdc-fc0ce7cbf452/image.png)\n\n"},{"excerpt":"Tech Environment Python v3.12 actions/checkout@v3 actions/setup-python@v3 python code의 의존성을 위해 requirements.txt로 라이브러리 설치 member_list.json 해당 파일에 멤버 리스트를 등록하여 사용합니다. 이와 같은 형식으로 등록합니다. PR notificaiton…","fields":{"slug":"/github-slack-bot/"},"frontmatter":{"date":"February 27, 2024","title":"PR 리뷰어 할당 봇 만들기","tags":["github-action","자동화"]},"rawMarkdownBody":"\n## Tech Environment\n\n- Python v3.12\n- actions/checkout@v3\n- actions/setup-python@v3\n- python code의 의존성을 위해 requirements.txt로 라이브러리 설치\n\n## member_list.json\n\n해당 파일에 멤버 리스트를 등록하여 사용합니다.\n\n```json\n[\n  {\n    \"githubName\": \"CEethan\",\n    \"slackUserId\": \"U069RPHRU95\"\n  },\n  {\n    \"githubName\": \"EeeasyCode\",\n    \"slackUserId\": \"U069RPHRU95\"\n  }\n]\n```\n\n이와 같은 형식으로 등록합니다.\n\n---\n\n## PR notificaiton bot\n\n> 지정한 레포지토리의 PR이 남아있는지 확인 후, 평일 지정한 시간에 Slack을 통해 알림을 전송하는 Bot 입니다.\n\n### Code Description\n\n### pr-notification.py\n\n- python 코드로 slack, github 연동\n- github repository 정보를 가져와 slack 메시지 형태로 가공\n- 가공된 메시지를 지정한 slack 채널로 전송\n\n### pr-notification-bot.yml\n\n- schedule -> cron 표현식을 통해 지정한 시간마다 동작하도록\n  스케줄링\n- 이후, github secret을 사용해 env 값 설정\n- github action을 활용하여 pr-notification.py를 실행\n\n---\n\n## assign reviewer bot\n\n> PR을 올리면 랜덤으로 리뷰어가 할당되어 Slack을 통해 알림받을 수 있습니다.\n\n### Code Description\n\n### assign-reviewer.py\n\n- python 코드로 slack, github 연동\n- python 내부 로직에 의해, 자동으로 리뷰어를 할당하여 등록함\n- 리뷰어로 할당된 멤버에게 Slack 메시지 전송\n\n### assign-reviewer-bot.yml\n\n- PR 이벤트를 감지하여 PR이 올라올 경우 해당 action 트리거\n- 이후, github secret을 사용해 env 값 설정\n- github action을 활용하여 assign-reviewer.py를 실행\n\n---\n\n## review check bot\n\n> 리뷰어가 PR에 대한 리뷰를 완료하면 PR 담당자에게 Slack 메시지를 전송합니다.\n\n### Code Description\n\n### review-check.py\n\n- python 코드로 slack, github 연동\n- python 내부 로직에 의해 PR 담당자에게 리뷰가 되었음을 알림\n\n### review-check-bot.yml\n\n- PR의 리뷰 이벤트를 감지하여 리뷰가 등록된 경우 해당 action\n  트리거\n- 이후, github secret을 사용해 env 값 설정\n- github action을 활용하여 review-check.py를 실행\n"},{"excerpt":"동시에 같은 DB 테이블 row를 업데이트 하는 상황은 \"DB의 동시성 이슈\"으로 생각해보면 좋을 것 같다. DB의 동시성 이슈 동시성이란 여러 요청이 동시에 동일한 자원(Data)에 접근하고 수정하려는 것을 말한다. 이로 인해, 발생하게 되는 문제를 동시성 문제라고 한다. 동시성 문제로 Data의 무결성이 깨지고 의도하지 않은 결과를 반환하게 되는 문제…","fields":{"slug":"/concurrency-issue/"},"frontmatter":{"date":"February 16, 2024","title":"동시성 이슈 해결해보기","tags":["database","문제해결"]},"rawMarkdownBody":"\n동시에 같은 DB 테이블 row를 업데이트 하는 상황은 <Strong>\"DB의 동시성 이슈\"</Strong>으로 생각해보면 좋을 것 같다.\n\n# DB의 동시성 이슈\n\n<Strong>동시성</Strong>이란 여러 요청이 동시에 동일한 자원(Data)에 접근하고 수정하려는 것을 말한다. 이로 인해, 발생하게 되는 문제를 동시성 문제라고 한다. 동시성 문제로 Data의 무결성이 깨지고 의도하지 않은 결과를 반환하게 되는 문제들이 발생한다.\n\n<hr>\n\n# 해결방안\n\n해결방안에는 DB수준에서의 락, 프레임워크 or 언어 수준에서의 동기화 등이 존재한다. 여기서는 DB수준에서의 락에 대해 알아보려고 한다.\n\n> 1. 테이블의 row에 접근 시, Lock을 걸고 다른 Lock이 걸려있지 않는 경우에만 수정을 가능하게 함\n> 2. 수정할 때 내가 먼저 수정했음을 명시하여 다른 곳에서 동일한 조건으로 값을 수정할 수 없게 함\n\n위처럼, 자원 경쟁에 대한 관점으로 두 가지의 방법을 생각해볼 수 있다. 이는 비관적 락과 낙관적 락을 나누는 기준이 된다.\n\n<hr>\n\n## 비관적 락(Pessimistic Lock)\n\n현재 수정하려는 data가 언제든지 다른 요청에 의해 수정될 가능성을 고려하여 해당 data에 Lock을 거는 방식\n트랜잭션이 시작될 때 Shared Lock 또는 Exclusive Lock을 걸고 시작한다.\n\n- <code><Strong>공유락 (Shared Lock)</Strong></code> : Read Lock이라고 하는 공유락은 트랜잭션이 읽기를 할 때 사용하는 락이며, 데이터를 읽기만 하기 때문에 같은 공유락끼리는 동시에 접근이 가능하지만, 쓰기 작업은 막는다.\n\n- <code><Strong>베타락 (Exclusive Lock)</Strong></code> : Write Lock이라고 하는 배터락은, 데이터를 변경할 때 사용하는 락이다. 트랜잭션이 완료될 때까지 유지되며, 락이 끝나기 전까지 읽기/쓰기를 모두 막는다.\n\n### 장점\n\n- data의 무결성을 보존할 수 있다.\n- 충돌 발생 미리 방지\n\n### 단점\n\n- Lock으로 인해 이후의 다른 요청은 대기 상태로 빠짐\n- 기존 Lock의 트랜잭션이 commit/rollback으로 끝내면 이후 대기 요청을 실행\n\n<hr>\n\n## 낙관적 락(Optimistic Lock)\n\n자원에 락을 걸지 않고, 동시성 문제가 발생하면 그때 처리한다.\n숫자/시간 컬럼을 만들어 수정 시 그 data를 증가/갱신함 -> data 수정 시 컬럼을 비교하여 일치하는지 확인\n\n- Version과 같은 <Strong>별도의 컬럼을 추가</Strong>하여 충돌 발생을 막는다.\n  Version -> hashcode / timestamp 등을 사용하여 상태를 보고 충돌 확인함\n\n- 충돌 발생 시, DB가 아닌 애플리케이션 단에서 처리를 한다.\n  낙관적 락은 UPDATE에 실패해도 자동으로 예외를 던지지 않고, 단순히 0개의 row를 업데이트한다.\n  따라서 이때 여러 작업이 묶은 트랜잭션 요청 실패 시,<Strong>우리가 직접 롤백 처리</Strong>를 해줘야 한다.\n\n### 장점\n\n- 구현하기 용이함\n- 지속적인 락으로 인한 성능저하를 막을 수 있음\n\n### 단점\n\n- Version Conflict 시, 처리해야 할 외부 요인이 존재함\n\n<hr>\n\n## 성능 비교\n\n> <Strong>비관적 락 < 낙관적 락 </Strong>\n\n- 낙관적 락은 트랜잭션이 필요하지 않기 때문에 성능적으로 우수함\n- 비관적 락은 데이터 자체에 락을 걸기 때문에 동시성이 떨어져 성능 저하가 발생하며, 서로의 자원이 필요할 경우에는 교착상태가 발생할 가능성 존재\n\n> <Strong>충돌이 많이 발생하는 환경</Strong>\n\n충돌 발생 시, 비관적 락은 트랜잭션을 롤백하면 끝남. 하지만 낙관적 락은 까다로운 수동 롤백 처리와 성능 측면에서도 Update를 한번씩 더 해줘야 하기 떄문에, 성능 저하가 발생할 수 있음\n\n<Strong> 데이터의 무결성 + 데이터의 충돌이 많이 발생할 것 같은 경우 -> 비관적 락\n데이터 충돌이 적을 것 같은 경우 + 조회 작업이 많아 동시 접근 성능이 중요 -> 낙관적 락 </Strong>\n"},{"excerpt":"이번에 진행한 프로젝트에서 나는 CloudType을 사용하여 NestJS 기반 서버를 무료로 배포하였다. 무료로 서버를 배포할 수 있다는 것이 정말 큰 장점이었지만, CloudType의 무료 티어의 경우 연속 실행 제한이 걸려 매일 오전 3~9시 사이 프리티어로 구동 중인 서비스는 자동으로 중지 상태로 변경되는 문제가 존재한다.  사실, 정지되는 것은 문…","fields":{"slug":"/github-healthcheck-bot/"},"frontmatter":{"date":"December 27, 2023","title":"github-action + slack으로 서버 헬스체크하기","tags":["github-action","자동화"]},"rawMarkdownBody":"\n이번에 진행한 프로젝트에서 나는 CloudType을 사용하여 NestJS 기반 서버를 무료로 배포하였다. 무료로 서버를 배포할 수 있다는 것이 정말 큰 장점이었지만, CloudType의 무료 티어의 경우 **연속 실행 제한**이 걸려 매일 오전 3~9시 사이 프리티어로 구동 중인 서비스는 자동으로 중지 상태로 변경되는 문제가 존재한다.\n\n![](https://velog.velcdn.com/images/eeeasy-code/post/227fe906-018a-41b5-92e3-25f37f0a37c8/image.png)\n\n사실, 정지되는 것은 문제가 되지 않았다. 웹 사이트에 접속하는 사용자의 수도 많지 않았고, 오전 3~9시 사이에 접속하는 사용자는 더욱 낮을 것이라고 판단했기 때문이다. 그럼에도 일단 언제 중지될지 모르는 서버와 꺼져있는 서버를 재가동시키는 것을 깜빡하는 경우에 소중한 사용자의 데이터가 저장되지 못하는 일이 발생했다. 프로젝트 배포에서 가장 중요했던 사용자의 구매량과 버튼 클릭 수를 DB 서버에 저장하고 있었기에 이는 우리에게 나름 크리티컬한 문제가 되었다.\n\n## 대응 방안\n\n일단 초기 대응 방안은 그저 9시 이후에 CloudType 프로젝트 관리창에서 꺼져있는 나의 서버를 다시 켰다. 그런데 가끔 9시 이후에도 잘 켜져있다가 이후에 꺼지는 경우도 있었던 것으로 기억한다. 그래서, 언제꺼질지 몰라 지속적으로 확인했었다. 이는 너무 귀찮기도 했고 짜증나기도 했다. 그렇게 점점 서버 재가동을 놓치는 시간이 많아졌고, 서버는 잠들어 있는 시간이 더 길어졌다.\n\n문제를 해결하기 위해, 아이디어를 구상해 보았다.\n\n> 1. 서버 중단 시, 내부 로직에 중단되기 직전 메일 등의 알림 기능을 구현\n> 2. 프론트엔드 단에서 서버의 응답이 정상적으로 오지않을 경우를 확인\n> 3. 헬스체크 서버를 구현 후 배포하여 주기적으로 확인\n\n내 머리 속에 든 생각은 총 3가지였다. 우선 첫 번째 아이디어를 진행보았다. 서버 내부 메인 로직에 아래와 같은 코드를 넣어 서버가 다운될 시점에 로그 파일을 남길 수 있도록 진행했다.\n\n```\nprocess.on('exit', code => {\n  console.log(code)\n  logger.log({\n    level: 'error',\n    message: 'exit'\n  })\n})\n\nprocess.on('SIGINT', code => {\n  console.log(code)\n  logger.log({\n    level: 'error',\n    message: 'sigint'\n  })\n})\n```\n\n하지만, 서버가 중단되고 재가동 후 확인해본 결과 로그 파일은 생성되지 않았다. 그 원인에 대해 아직도 명확한 해답을 찾지는 못했지만 스스로 생각해본 결과 배포 시스템이 중단되는 것과 내부 로직은 관련이 없고, AWS처럼 시스템 중단 시 발생하는 이벤트가 존재할텐데 이를 활용해야 할 것 같다는 생각이 들었다. CloudType 공식문서에는 따로 나와있는 내용이 없었다.\n\n두 번째 아이디어는 프론트엔드 단에서 내가 배포한 서버의 API를 호출했을 때, 응답이 정상적으로 오지않고 500 등의 에러를 응답할 경우에 알림을 보내는 기능을 생각해봤다. 사실 이 아이디어도 나름 깔끔하고 좋다고 생각했지만, 프론트엔드 개발자 분께서 본인의 코드를 건드는 것을 별로 좋아하지 않았고 그래서 일단 내가 스스로 해결해보려 노력해봤다.\n\n마지막 아이디어를 지금 채택해 사용 중인데, 초기에 생각했던 것은 헬스체크 서버에 기존 서버의 헬스체크 Api를 스케줄링하는 기능을 구현해 배포하려고 했다. 생각해보니 그럼 서버가 두 개나 띄워져있는 것인데 이는 낭비라고 생각이 들었다. 그래서 찾은 방법이 ** Github Action으로 헬스 체크**하는 것이었다. Github Action으로 스케줄링을 걸어놓고 특정 시간에 한 번씩 서버의 상태를 확인하고, 이를 Slack으로 알림을 전송하는 것을 생각했다.\n\n## Github Action으로 헬스체크\n\ngithub action에 등록한 헬스체크 기능을 코드로 먼저 보겠다.\n\n```\nname: health check\n\non:\n  # 스케줄링을 설정함 / 매분마다 한 번씩 이벤트를 트리거함\n  schedule:\n    - cron: '*/1 * * * *'\n  # workflow_dispath는 수동으로 이벤트를 트리거할 수 있도록 해주는 것을 의미함\n  workflow_dispatch:\n\njobs:\n  healthcheck:\n    runs-on: ubuntu-latest\n    steps:\n      # 지정한 서버에 대해 헬스 체크 진행\n      - name: Release API Health Check\n        uses: jtalk/url-health-check-action@v3\n        with:\n          github_token: ${{ secrets.GHP_TOKEN }}\n          url: ${{ secrets.RELEASE_URI }}\n          max-attempts: 3 # 시도 횟수\n          retry-delay: 1s # 시도 간격\n\n\t  # 트리거된 이벤트의 내용을 slack으로 전달\n      - name: action-slack\n        uses: 8398a7/action-slack@v3\n        with:\n          status: ${{ job.status }}\n          github_token: ${{ secrets.GHP_TOKEN }}\n          author_name: Github Action Health Check\n          fields: repo,message,commit,action,eventName,ref,workflow,job,took # 보낼 정보들\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEB_HOOK_URL }}\n        if: always() # 특정 조건에 상관없이 항상 실행\n\n```\n\n작성된 github action의 healthCheck 플로우는 다음과 같다. 이 후, slack의 incoming-webhook을 등록하여 진행하면 문제없이 서버의 healthCheck 기능이 정상적으로 작동된다. 덕분에 서버가 중단된 경우 Slack을 통해 알림을 받을 수 있게 되었고, 귀찮게 내가 한번씩 접속해서 서버가 중단되었는지 확인하지 않아도 알 수 있게 되어 너무 편하다.\n\n| 서버 정상 작동                                                                                       | 서버 중단 시                                                                                         |\n| ---------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n| ![](https://velog.velcdn.com/images/eeeasy-code/post/2ff2fd43-d7ec-4cb7-98b4-1618a3ac1b7b/image.png) | ![](https://velog.velcdn.com/images/eeeasy-code/post/0db7fdfe-7582-4679-bd0c-eb87353f6925/image.png) |\n\n![](https://velog.velcdn.com/images/eeeasy-code/post/81ed5cf4-526b-4085-98c3-9d4c04d9a76e/image.png)\n\n## 발생한 문제들\n\n1. Github Action에서 발생하는 <code>\"Resource not accessible by integration\"</code> 문제 발생 -> github token을 넣어주면 해결 가능\n2. <code>\"The process '/usr/bin/git' failed with exit code 1\"</code> 문제 발생 -> healthCheck할 서버의 url이 정상적인 응답을 보내는지 확인 후 설정\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}